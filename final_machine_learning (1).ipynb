{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial data read-in/prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn \n",
    "\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update tensorflow. \n",
    "\n",
    "# !pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn import preprocessing\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "import os\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python._pywrap_tensorflow_internal' has no attribute 'IsGoogleCudaEnabled'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-1901b0db022a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;31m# pylint: disable=wildcard-import,g-bad-import-order,g-import-not-at-top\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meager\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;31m# pylint: enable=wildcard-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprotobuf\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrewriter_config_pb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tfe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclient\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tfe.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;31m# pylint: disable=invalid-import-order,g-bad-import-order, wildcard-import, unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pywrap_tfe\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0m_default_dlopen_flags\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetdlopenflags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetdlopenflags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_default_dlopen_flags\u001b[0m \u001b[1;33m|\u001b[0m \u001b[0mctypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRTLD_GLOBAL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpywrap_tensorflow_internal\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m__git_version__\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\tensorflow\\python\\pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mIsGoogleCudaEnabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIsGoogleCudaEnabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m \u001b[0mIsGoogleCudaEnabled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_pywrap_tensorflow_internal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIsGoogleCudaEnabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mCudaSupportsHalfMatMulAndConv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'tensorflow.python._pywrap_tensorflow_internal' has no attribute 'IsGoogleCudaEnabled'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>year</th>\n",
       "      <th>Name</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>700703</td>\n",
       "      <td>69014</td>\n",
       "      <td>9.292239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6337373</td>\n",
       "      <td>50752</td>\n",
       "      <td>15.835820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2895928</td>\n",
       "      <td>40149</td>\n",
       "      <td>17.846507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>California</td>\n",
       "      <td>36969200</td>\n",
       "      <td>61632</td>\n",
       "      <td>14.096818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   State  year        Name  Population    HHI  PovertyRate\n",
       "0      1  2011     Alabama     4747424  42934    17.133186\n",
       "1      2  2011      Alaska      700703  69014     9.292239\n",
       "2      4  2011     Arizona     6337373  50752    15.835820\n",
       "3      5  2011    Arkansas     2895928  40149    17.846507\n",
       "4      6  2011  California    36969200  61632    14.096818"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the census csv into a pandas DataFrame\n",
    "\n",
    "census = pd.read_csv('../Resources/Tableau_clean/census_all.csv')\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>year</th>\n",
       "      <th>state_name</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>700703</td>\n",
       "      <td>69014</td>\n",
       "      <td>9.292239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>6337373</td>\n",
       "      <td>50752</td>\n",
       "      <td>15.835820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2895928</td>\n",
       "      <td>40149</td>\n",
       "      <td>17.846507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2011</td>\n",
       "      <td>California</td>\n",
       "      <td>36969200</td>\n",
       "      <td>61632</td>\n",
       "      <td>14.096818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>51</td>\n",
       "      <td>2015</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>8256630</td>\n",
       "      <td>65015</td>\n",
       "      <td>11.164628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>53</td>\n",
       "      <td>2015</td>\n",
       "      <td>Washington</td>\n",
       "      <td>6985464</td>\n",
       "      <td>61062</td>\n",
       "      <td>13.005750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>54</td>\n",
       "      <td>2015</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>1851420</td>\n",
       "      <td>41751</td>\n",
       "      <td>17.466809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>55</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>5742117</td>\n",
       "      <td>53357</td>\n",
       "      <td>12.614651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     State  year     state_name  Population    HHI  PovertyRate\n",
       "0        1  2011        Alabama     4747424  42934    17.133186\n",
       "1        2  2011         Alaska      700703  69014     9.292239\n",
       "2        4  2011        Arizona     6337373  50752    15.835820\n",
       "3        5  2011       Arkansas     2895928  40149    17.846507\n",
       "4        6  2011     California    36969200  61632    14.096818\n",
       "..     ...   ...            ...         ...    ...          ...\n",
       "250     51  2015       Virginia     8256630  65015    11.164628\n",
       "251     53  2015     Washington     6985464  61062    13.005750\n",
       "252     54  2015  West Virginia     1851420  41751    17.466809\n",
       "253     55  2015      Wisconsin     5742117  53357    12.614651\n",
       "254     56  2015        Wyoming      579679  58840    11.212240\n",
       "\n",
       "[255 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename State column for joining\n",
    "\n",
    "census = census.rename(columns={'Name': 'state_name'})\n",
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>year</th>\n",
       "      <th>state_name</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>average_diabetic_enrollees_hemoglobin_a1c_test</th>\n",
       "      <th>average_diabetic_enrollees_eye_exam</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "      <th>average_female_enrollees_age_67_to_69</th>\n",
       "      <th>average_female_age_67_to_69_mammogram</th>\n",
       "      <th>beneficiaries_part_a_eligible</th>\n",
       "      <th>leg_amputations_per_1000_enrollees</th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>63.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>42267.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>501422.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>49648.0</td>\n",
       "      <td>70.9</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>55.8</td>\n",
       "      <td>66.9</td>\n",
       "      <td>5151.0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>54928.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>53.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>465298.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>50991.0</td>\n",
       "      <td>78.5</td>\n",
       "      <td>66.1</td>\n",
       "      <td>75.8</td>\n",
       "      <td>43614.0</td>\n",
       "      <td>64.3</td>\n",
       "      <td>501103.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>327939.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>40202.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>66.1</td>\n",
       "      <td>76.2</td>\n",
       "      <td>29290.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>345431.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>California</td>\n",
       "      <td>2238140.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>243999.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>64.1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>190971.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2378472.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>49.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>49.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>832699.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>98165.0</td>\n",
       "      <td>87.6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>83135.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>703266.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>42.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Washington</td>\n",
       "      <td>610922.0</td>\n",
       "      <td>78.5</td>\n",
       "      <td>56474.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>67.7</td>\n",
       "      <td>76.3</td>\n",
       "      <td>56238.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>510796.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>206961.0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>84.7</td>\n",
       "      <td>59.9</td>\n",
       "      <td>78.2</td>\n",
       "      <td>20777.0</td>\n",
       "      <td>59.1</td>\n",
       "      <td>171837.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>474364.0</td>\n",
       "      <td>79.8</td>\n",
       "      <td>46596.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>81.6</td>\n",
       "      <td>44595.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>418646.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.5</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58899.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state_id  year     state_name  beneficiaries_part_b  \\\n",
       "0         1.0  2011        Alabama              478784.0   \n",
       "1         2.0  2011         Alaska               49648.0   \n",
       "2         3.0  2011        Arizona              465298.0   \n",
       "3         4.0  2011       Arkansas              327939.0   \n",
       "4         5.0  2011     California             2238140.0   \n",
       "..        ...   ...            ...                   ...   \n",
       "250      49.0  2015       Virginia              832699.0   \n",
       "251      50.0  2015     Washington              610922.0   \n",
       "252      51.0  2015  West Virginia              206961.0   \n",
       "253      52.0  2015      Wisconsin              474364.0   \n",
       "254      53.0  2015        Wyoming               72959.0   \n",
       "\n",
       "     one_ambulatory_visit  diabetic_enrollees_age_65_to_75  \\\n",
       "0                    82.5                          69691.0   \n",
       "1                    70.9                           5449.0   \n",
       "2                    78.2                          50991.0   \n",
       "3                    80.7                          40202.0   \n",
       "4                    72.7                         243999.0   \n",
       "..                    ...                              ...   \n",
       "250                  83.3                          98165.0   \n",
       "251                  78.5                          56474.0   \n",
       "252                  80.8                          29239.0   \n",
       "253                  79.8                          46596.0   \n",
       "254                  72.7                           6146.0   \n",
       "\n",
       "     average_diabetic_enrollees_hemoglobin_a1c_test  \\\n",
       "0                                              83.9   \n",
       "1                                              74.5   \n",
       "2                                              78.5   \n",
       "3                                              82.5   \n",
       "4                                              80.6   \n",
       "..                                              ...   \n",
       "250                                            87.6   \n",
       "251                                            86.6   \n",
       "252                                            84.7   \n",
       "253                                            91.0   \n",
       "254                                            78.2   \n",
       "\n",
       "     average_diabetic_enrollees_eye_exam  \\\n",
       "0                                   63.3   \n",
       "1                                   55.8   \n",
       "2                                   66.1   \n",
       "3                                   66.1   \n",
       "4                                   64.1   \n",
       "..                                   ...   \n",
       "250                                 70.0   \n",
       "251                                 67.7   \n",
       "252                                 59.9   \n",
       "253                                 69.7   \n",
       "254                                 62.8   \n",
       "\n",
       "     average_diabetic_enrollees_blood_lipids_test  \\\n",
       "0                                            80.3   \n",
       "1                                            66.9   \n",
       "2                                            75.8   \n",
       "3                                            76.2   \n",
       "4                                            78.0   \n",
       "..                                            ...   \n",
       "250                                          82.0   \n",
       "251                                          76.3   \n",
       "252                                          78.2   \n",
       "253                                          81.6   \n",
       "254                                          59.5   \n",
       "\n",
       "     average_female_enrollees_age_67_to_69  \\\n",
       "0                                  42267.0   \n",
       "1                                   5151.0   \n",
       "2                                  43614.0   \n",
       "3                                  29290.0   \n",
       "4                                 190971.0   \n",
       "..                                     ...   \n",
       "250                                83135.0   \n",
       "251                                56238.0   \n",
       "252                                20777.0   \n",
       "253                                44595.0   \n",
       "254                                 7201.0   \n",
       "\n",
       "     average_female_age_67_to_69_mammogram  beneficiaries_part_a_eligible  \\\n",
       "0                                     62.8                       501422.0   \n",
       "1                                     55.3                        54928.0   \n",
       "2                                     64.3                       501103.0   \n",
       "3                                     58.3                       345431.0   \n",
       "4                                     59.0                      2378472.0   \n",
       "..                                     ...                            ...   \n",
       "250                                   64.5                       703266.0   \n",
       "251                                   60.0                       510796.0   \n",
       "252                                   59.1                       171837.0   \n",
       "253                                   71.9                       418646.0   \n",
       "254                                   56.0                        58899.0   \n",
       "\n",
       "     leg_amputations_per_1000_enrollees  \\\n",
       "0                                  0.99   \n",
       "1                                  0.81   \n",
       "2                                  0.57   \n",
       "3                                  0.85   \n",
       "4                                  0.63   \n",
       "..                                  ...   \n",
       "250                                0.53   \n",
       "251                                0.46   \n",
       "252                                0.90   \n",
       "253                                0.65   \n",
       "254                                0.39   \n",
       "\n",
       "     discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \n",
       "0                                                 76.4                   \n",
       "1                                                 53.1                   \n",
       "2                                                 51.4                   \n",
       "3                                                 77.0                   \n",
       "4                                                 49.9                   \n",
       "..                                                 ...                   \n",
       "250                                               42.8                   \n",
       "251                                               32.7                   \n",
       "252                                               75.0                   \n",
       "253                                               45.0                   \n",
       "254                                               43.1                   \n",
       "\n",
       "[255 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the medicare csv into a pandas DataFrame\n",
    "\n",
    "medicare = pd.read_csv('../Resources/Tableau_clean/medicare_all.csv')\n",
    "medicare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_id',\n",
       " 'year',\n",
       " 'state_name',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names for joining\n",
    "\n",
    "list(medicare.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>year_x</th>\n",
       "      <th>state_name</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "      <th>state_id</th>\n",
       "      <th>year_y</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>average_diabetic_enrollees_hemoglobin_a1c_test</th>\n",
       "      <th>average_diabetic_enrollees_eye_exam</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "      <th>average_female_enrollees_age_67_to_69</th>\n",
       "      <th>average_female_age_67_to_69_mammogram</th>\n",
       "      <th>beneficiaries_part_a_eligible</th>\n",
       "      <th>leg_amputations_per_1000_enrollees</th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>63.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>42267.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>501422.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>492195.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>72392.0</td>\n",
       "      <td>84.2</td>\n",
       "      <td>63.2</td>\n",
       "      <td>80.7</td>\n",
       "      <td>42535.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>517526.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>71.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>498123.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>74492.0</td>\n",
       "      <td>84.9</td>\n",
       "      <td>63.8</td>\n",
       "      <td>81.8</td>\n",
       "      <td>44502.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>525015.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>506023.0</td>\n",
       "      <td>83.2</td>\n",
       "      <td>76238.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>63.7</td>\n",
       "      <td>81.1</td>\n",
       "      <td>48751.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>534296.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>510586.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>68202.0</td>\n",
       "      <td>86.1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>52169.0</td>\n",
       "      <td>63.1</td>\n",
       "      <td>404987.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>61634.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>64.7</td>\n",
       "      <td>58.7</td>\n",
       "      <td>5517.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>65932.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>55.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2012</td>\n",
       "      <td>64431.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>6017.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>63.8</td>\n",
       "      <td>59.4</td>\n",
       "      <td>5519.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>69056.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>52.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2013</td>\n",
       "      <td>68066.0</td>\n",
       "      <td>74.6</td>\n",
       "      <td>6475.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.2</td>\n",
       "      <td>5844.0</td>\n",
       "      <td>57.1</td>\n",
       "      <td>73043.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2014</td>\n",
       "      <td>70457.0</td>\n",
       "      <td>73.8</td>\n",
       "      <td>6832.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>63.2</td>\n",
       "      <td>59.7</td>\n",
       "      <td>6498.0</td>\n",
       "      <td>56.3</td>\n",
       "      <td>75824.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>46.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>56</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.5</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58899.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      State  year_x state_name  Population    HHI  PovertyRate  state_id  \\\n",
       "0         1    2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "1         1    2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "2         1    2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "3         1    2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "4         1    2011    Alabama     4747424  42934    17.133186       1.0   \n",
       "...     ...     ...        ...         ...    ...          ...       ...   \n",
       "1270     56    2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "1271     56    2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "1272     56    2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "1273     56    2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "1274     56    2015    Wyoming      579679  58840    11.212240      53.0   \n",
       "\n",
       "      year_y  beneficiaries_part_b  one_ambulatory_visit  \\\n",
       "0       2011              478784.0                  82.5   \n",
       "1       2012              492195.0                  82.8   \n",
       "2       2013              498123.0                  83.3   \n",
       "3       2014              506023.0                  83.2   \n",
       "4       2015              510586.0                  83.3   \n",
       "...      ...                   ...                   ...   \n",
       "1270    2011               61634.0                  73.0   \n",
       "1271    2012               64431.0                  73.3   \n",
       "1272    2013               68066.0                  74.6   \n",
       "1273    2014               70457.0                  73.8   \n",
       "1274    2015               72959.0                  72.7   \n",
       "\n",
       "      diabetic_enrollees_age_65_to_75  \\\n",
       "0                             69691.0   \n",
       "1                             72392.0   \n",
       "2                             74492.0   \n",
       "3                             76238.0   \n",
       "4                             68202.0   \n",
       "...                               ...   \n",
       "1270                           5750.0   \n",
       "1271                           6017.0   \n",
       "1272                           6475.0   \n",
       "1273                           6832.0   \n",
       "1274                           6146.0   \n",
       "\n",
       "      average_diabetic_enrollees_hemoglobin_a1c_test  \\\n",
       "0                                               83.9   \n",
       "1                                               84.2   \n",
       "2                                               84.9   \n",
       "3                                               85.0   \n",
       "4                                               86.1   \n",
       "...                                              ...   \n",
       "1270                                            74.7   \n",
       "1271                                            74.7   \n",
       "1272                                            75.4   \n",
       "1273                                            76.7   \n",
       "1274                                            78.2   \n",
       "\n",
       "      average_diabetic_enrollees_eye_exam  \\\n",
       "0                                    63.3   \n",
       "1                                    63.2   \n",
       "2                                    63.8   \n",
       "3                                    63.7   \n",
       "4                                    64.0   \n",
       "...                                   ...   \n",
       "1270                                 64.7   \n",
       "1271                                 63.8   \n",
       "1272                                 62.7   \n",
       "1273                                 63.2   \n",
       "1274                                 62.8   \n",
       "\n",
       "      average_diabetic_enrollees_blood_lipids_test  \\\n",
       "0                                             80.3   \n",
       "1                                             80.7   \n",
       "2                                             81.8   \n",
       "3                                             81.1   \n",
       "4                                             81.0   \n",
       "...                                            ...   \n",
       "1270                                          58.7   \n",
       "1271                                          59.4   \n",
       "1272                                          60.2   \n",
       "1273                                          59.7   \n",
       "1274                                          59.5   \n",
       "\n",
       "      average_female_enrollees_age_67_to_69  \\\n",
       "0                                   42267.0   \n",
       "1                                   42535.0   \n",
       "2                                   44502.0   \n",
       "3                                   48751.0   \n",
       "4                                   52169.0   \n",
       "...                                     ...   \n",
       "1270                                 5517.0   \n",
       "1271                                 5519.0   \n",
       "1272                                 5844.0   \n",
       "1273                                 6498.0   \n",
       "1274                                 7201.0   \n",
       "\n",
       "      average_female_age_67_to_69_mammogram  beneficiaries_part_a_eligible  \\\n",
       "0                                      62.8                       501422.0   \n",
       "1                                      62.7                       517526.0   \n",
       "2                                      62.7                       525015.0   \n",
       "3                                      62.8                       534296.0   \n",
       "4                                      63.1                       404987.0   \n",
       "...                                     ...                            ...   \n",
       "1270                                   57.4                        65932.0   \n",
       "1271                                   57.9                        69056.0   \n",
       "1272                                   57.1                        73043.0   \n",
       "1273                                   56.3                        75824.0   \n",
       "1274                                   56.0                        58899.0   \n",
       "\n",
       "      leg_amputations_per_1000_enrollees  \\\n",
       "0                                   0.99   \n",
       "1                                   0.90   \n",
       "2                                   0.87   \n",
       "3                                   0.83   \n",
       "4                                   0.79   \n",
       "...                                  ...   \n",
       "1270                                0.62   \n",
       "1271                                0.46   \n",
       "1272                                0.67   \n",
       "1273                                0.38   \n",
       "1274                                0.39   \n",
       "\n",
       "      discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \n",
       "0                                                  76.4                   \n",
       "1                                                  71.5                   \n",
       "2                                                  65.4                   \n",
       "3                                                  61.1                   \n",
       "4                                                  62.0                   \n",
       "...                                                 ...                   \n",
       "1270                                               55.2                   \n",
       "1271                                               52.7                   \n",
       "1272                                               47.9                   \n",
       "1273                                               46.1                   \n",
       "1274                                               43.1                   \n",
       "\n",
       "[1275 rows x 19 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join csvs\n",
    "\n",
    "data_all = pd.merge(census,\n",
    "                 medicare[['state_id', 'year', 'state_name', 'beneficiaries_part_b', 'one_ambulatory_visit', 'diabetic_enrollees_age_65_to_75',\n",
    " 'average_diabetic_enrollees_hemoglobin_a1c_test', 'average_diabetic_enrollees_eye_exam', 'average_diabetic_enrollees_blood_lipids_test',\n",
    " 'average_female_enrollees_age_67_to_69', 'average_female_age_67_to_69_mammogram', 'beneficiaries_part_a_eligible', 'leg_amputations_per_1000_enrollees',\n",
    " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees']],\n",
    "                 on='state_name')\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['State',\n",
       " 'year_x',\n",
       " 'state_name',\n",
       " 'Population',\n",
       " 'HHI',\n",
       " 'PovertyRate',\n",
       " 'state_id',\n",
       " 'year_y',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get list of column names\n",
    "\n",
    "list(data_all.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['Population', 'PovertyRate', 'beneficiaries_part_b', 'one_ambulatory_visit',\n",
    " 'diabetic_enrollees_age_65_to_75',  'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
    " 'average_diabetic_enrollees_eye_exam', 'average_diabetic_enrollees_blood_lipids_test',\n",
    " 'average_female_enrollees_age_67_to_69', 'average_female_age_67_to_69_mammogram', 'beneficiaries_part_a_eligible',\n",
    " 'leg_amputations_per_1000_enrollees', 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "\n",
    "y = data_all[\"HHI\"]\n",
    "X = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>PovertyRate</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>average_diabetic_enrollees_hemoglobin_a1c_test</th>\n",
       "      <th>average_diabetic_enrollees_eye_exam</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "      <th>average_female_enrollees_age_67_to_69</th>\n",
       "      <th>average_female_age_67_to_69_mammogram</th>\n",
       "      <th>beneficiaries_part_a_eligible</th>\n",
       "      <th>leg_amputations_per_1000_enrollees</th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>6899123</td>\n",
       "      <td>13.282326</td>\n",
       "      <td>545956.0</td>\n",
       "      <td>78.3</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>68.4</td>\n",
       "      <td>80.0</td>\n",
       "      <td>45223.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>598856.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>44.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>561</th>\n",
       "      <td>9886095</td>\n",
       "      <td>16.447161</td>\n",
       "      <td>940574.0</td>\n",
       "      <td>79.8</td>\n",
       "      <td>126208.0</td>\n",
       "      <td>85.5</td>\n",
       "      <td>65.6</td>\n",
       "      <td>79.9</td>\n",
       "      <td>76285.0</td>\n",
       "      <td>65.6</td>\n",
       "      <td>990373.0</td>\n",
       "      <td>0.66</td>\n",
       "      <td>64.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>5982413</td>\n",
       "      <td>14.526513</td>\n",
       "      <td>578710.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>72934.0</td>\n",
       "      <td>85.6</td>\n",
       "      <td>67.1</td>\n",
       "      <td>79.7</td>\n",
       "      <td>48778.0</td>\n",
       "      <td>62.2</td>\n",
       "      <td>620963.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>64.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1125</th>\n",
       "      <td>624958</td>\n",
       "      <td>10.842489</td>\n",
       "      <td>80820.0</td>\n",
       "      <td>75.2</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>71.3</td>\n",
       "      <td>78.9</td>\n",
       "      <td>7095.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>86153.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>51.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>625904</td>\n",
       "      <td>11.323302</td>\n",
       "      <td>80820.0</td>\n",
       "      <td>75.2</td>\n",
       "      <td>7810.0</td>\n",
       "      <td>88.9</td>\n",
       "      <td>71.3</td>\n",
       "      <td>78.9</td>\n",
       "      <td>7095.0</td>\n",
       "      <td>70.3</td>\n",
       "      <td>86153.0</td>\n",
       "      <td>0.42</td>\n",
       "      <td>51.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Population  PovertyRate  beneficiaries_part_b  one_ambulatory_visit  \\\n",
       "1190     6899123    13.282326              545956.0                  78.3   \n",
       "561      9886095    16.447161              940574.0                  79.8   \n",
       "631      5982413    14.526513              578710.0                  79.0   \n",
       "1125      624958    10.842489               80820.0                  75.2   \n",
       "1135      625904    11.323302               80820.0                  75.2   \n",
       "\n",
       "      diabetic_enrollees_age_65_to_75  \\\n",
       "1190                          58138.0   \n",
       "561                          126208.0   \n",
       "631                           72934.0   \n",
       "1125                           7810.0   \n",
       "1135                           7810.0   \n",
       "\n",
       "      average_diabetic_enrollees_hemoglobin_a1c_test  \\\n",
       "1190                                            86.6   \n",
       "561                                             85.5   \n",
       "631                                             85.6   \n",
       "1125                                            88.9   \n",
       "1135                                            88.9   \n",
       "\n",
       "      average_diabetic_enrollees_eye_exam  \\\n",
       "1190                                 68.4   \n",
       "561                                  65.6   \n",
       "631                                  67.1   \n",
       "1125                                 71.3   \n",
       "1135                                 71.3   \n",
       "\n",
       "      average_diabetic_enrollees_blood_lipids_test  \\\n",
       "1190                                          80.0   \n",
       "561                                           79.9   \n",
       "631                                           79.7   \n",
       "1125                                          78.9   \n",
       "1135                                          78.9   \n",
       "\n",
       "      average_female_enrollees_age_67_to_69  \\\n",
       "1190                                45223.0   \n",
       "561                                 76285.0   \n",
       "631                                 48778.0   \n",
       "1125                                 7095.0   \n",
       "1135                                 7095.0   \n",
       "\n",
       "      average_female_age_67_to_69_mammogram  beneficiaries_part_a_eligible  \\\n",
       "1190                                   62.8                       598856.0   \n",
       "561                                    65.6                       990373.0   \n",
       "631                                    62.2                       620963.0   \n",
       "1125                                   70.3                        86153.0   \n",
       "1135                                   70.3                        86153.0   \n",
       "\n",
       "      leg_amputations_per_1000_enrollees  \\\n",
       "1190                                0.61   \n",
       "561                                 0.66   \n",
       "631                                 0.62   \n",
       "1125                                0.42   \n",
       "1135                                0.42   \n",
       "\n",
       "      discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \n",
       "1190                                               44.2                   \n",
       "561                                                64.5                   \n",
       "631                                                64.7                   \n",
       "1125                                               51.1                   \n",
       "1135                                               51.1                   "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 44  26  21 154  66 165 145 199  21 209  52 225  39 142  64 152   2 156\n",
      "  92 170 219  47 121 208 155  32 116  76 203  75   0  33 195  74 158 233\n",
      "  19 188  49  15 225 149 202 137 175 204  63  81  79 189  48 101 147 246\n",
      "  90 210 240  50  70 164 110 187  37  14 178 232 218 107 124 188 231 190\n",
      " 153   4 186 201 189  71 227 221 118  59  83 130 111 166  54 241 212  11\n",
      "  30 248  89  25 158 182  65  17 113  85 192  89 249 229  91 150  84  73\n",
      "  17 132 208 228 216 205 106 161 200  13 234  13 102 102 180  51 198  63\n",
      "  46 185 197  23 152 132 168 247  92  22  78 151 135 150 179 215  69 239\n",
      "  48 141  36 144 175   6 160 226   3 103 172 163  10  57 196 131 217  58\n",
      " 104 167  77 206  88 140  24 143 245 190 174  37  18 133 253 184 207  34\n",
      "  54 169 239 203  27  52 214 234 148 242  62 109   8 129 130 252 236 139\n",
      " 193 119 194 129 211 244 138  56 146 250 131 117 214 251 161 132  50  80\n",
      "  14 181  41  55  29  72 235  40 167 121  58 134 100  97  98 173   8  12\n",
      "   7  20 108 176 171 230 204 120  95 223  99  38 238 136  96 135 253  45\n",
      "   5  94 157  67  28 192  57 128  31  59  87 211  72 105  61   1 116 127\n",
      "  86 115 107 125 191 126  20  43 219 112 220 243  42 162 224  99 237  87\n",
      "  16  35 215 183 106   9 122 123 177  93 224  68   1 212  88 213  82 232\n",
      " 180 243  74 250 159  60  53 114 170  71 246 103 222]\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "\n",
    "\n",
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.4100418410041841\n",
      "Testing Data Score: 0.04075235109717868\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HHI = data_all[\"HHI\"].to_list()\n",
    "# HHI = data_all[\"HHI\"].array\n",
    "# HHI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.00      0.00      0.00         2\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.00      0.00      0.00         1\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.00      0.00      0.00         1\n",
      "           7       0.00      0.00      0.00         1\n",
      "           8       0.00      0.00      0.00         2\n",
      "           9       0.00      0.00      0.00         1\n",
      "          10       0.00      0.00      0.00         1\n",
      "          11       0.00      0.00      0.00         1\n",
      "          12       0.00      0.00      0.00         1\n",
      "          13       0.00      0.00      0.00         2\n",
      "          14       0.00      0.00      0.00         2\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         1\n",
      "          17       0.00      0.00      0.00         2\n",
      "          18       0.00      0.00      0.00         1\n",
      "          19       0.00      0.00      0.00         1\n",
      "          20       0.00      0.00      0.00         2\n",
      "          21       0.00      0.00      0.00         2\n",
      "          22       0.00      0.00      0.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         1\n",
      "          25       0.00      0.00      0.00         1\n",
      "          26       0.00      0.00      0.00         1\n",
      "          27       0.00      0.00      0.00         1\n",
      "          28       0.00      0.00      0.00         1\n",
      "          29       0.00      0.00      0.00         1\n",
      "          30       0.00      0.00      0.00         1\n",
      "          31       0.00      0.00      0.00         1\n",
      "          32       0.00      0.00      0.00         1\n",
      "          33       0.50      1.00      0.67         1\n",
      "          34       0.00      0.00      0.00         1\n",
      "          35       0.00      0.00      0.00         1\n",
      "          36       0.00      0.00      0.00         1\n",
      "          37       0.00      0.00      0.00         2\n",
      "          38       0.00      0.00      0.00         1\n",
      "          39       0.00      0.00      0.00         1\n",
      "          40       0.00      0.00      0.00         1\n",
      "          41       0.00      0.00      0.00         1\n",
      "          42       0.00      0.00      0.00         1\n",
      "          43       0.00      0.00      0.00         1\n",
      "          44       0.00      0.00      0.00         1\n",
      "          45       0.00      0.00      0.00         1\n",
      "          46       0.00      0.00      0.00         1\n",
      "          47       0.00      0.00      0.00         1\n",
      "          48       0.00      0.00      0.00         2\n",
      "          49       0.00      0.00      0.00         1\n",
      "          50       0.00      0.00      0.00         2\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.00      0.00      0.00         2\n",
      "          53       0.14      1.00      0.25         1\n",
      "          54       0.00      0.00      0.00         2\n",
      "          55       1.00      1.00      1.00         1\n",
      "          56       0.00      0.00      0.00         1\n",
      "          57       0.00      0.00      0.00         2\n",
      "          58       0.00      0.00      0.00         2\n",
      "          59       0.00      0.00      0.00         2\n",
      "          60       0.00      0.00      0.00         1\n",
      "          61       0.00      0.00      0.00         1\n",
      "          62       0.00      0.00      0.00         1\n",
      "          63       0.00      0.00      0.00         2\n",
      "          64       1.00      1.00      1.00         1\n",
      "          65       0.00      0.00      0.00         1\n",
      "          66       0.00      0.00      0.00         1\n",
      "          67       0.00      0.00      0.00         1\n",
      "          68       0.00      0.00      0.00         1\n",
      "          69       0.00      0.00      0.00         1\n",
      "          70       0.00      0.00      0.00         1\n",
      "          71       0.00      0.00      0.00         2\n",
      "          72       0.00      0.00      0.00         2\n",
      "          73       0.00      0.00      0.00         1\n",
      "          74       0.00      0.00      0.00         2\n",
      "          75       0.00      0.00      0.00         1\n",
      "          76       0.00      0.00      0.00         1\n",
      "          77       0.00      0.00      0.00         1\n",
      "          78       0.00      0.00      0.00         1\n",
      "          79       0.00      0.00      0.00         1\n",
      "          80       0.00      0.00      0.00         1\n",
      "          81       0.00      0.00      0.00         1\n",
      "          82       0.00      0.00      0.00         1\n",
      "          83       0.00      0.00      0.00         1\n",
      "          84       0.00      0.00      0.00         1\n",
      "          85       0.00      0.00      0.00         1\n",
      "          86       0.00      0.00      0.00         1\n",
      "          87       0.00      0.00      0.00         2\n",
      "          88       0.00      0.00      0.00         2\n",
      "          89       0.00      0.00      0.00         2\n",
      "          90       0.00      0.00      0.00         1\n",
      "          91       0.00      0.00      0.00         1\n",
      "          92       0.00      0.00      0.00         2\n",
      "          93       0.00      0.00      0.00         1\n",
      "          94       0.00      0.00      0.00         1\n",
      "          95       0.00      0.00      0.00         1\n",
      "          96       0.00      0.00      0.00         1\n",
      "          97       0.00      0.00      0.00         1\n",
      "          98       0.00      0.00      0.00         1\n",
      "          99       0.00      0.00      0.00         2\n",
      "         100       0.00      0.00      0.00         1\n",
      "         101       0.33      1.00      0.50         1\n",
      "         102       0.00      0.00      0.00         2\n",
      "         103       0.00      0.00      0.00         2\n",
      "         104       0.00      0.00      0.00         1\n",
      "         105       1.00      1.00      1.00         1\n",
      "         106       0.00      0.00      0.00         2\n",
      "         107       0.00      0.00      0.00         2\n",
      "         108       0.00      0.00      0.00         1\n",
      "         109       0.00      0.00      0.00         1\n",
      "         110       0.00      0.00      0.00         1\n",
      "         111       0.25      1.00      0.40         1\n",
      "         112       0.00      0.00      0.00         1\n",
      "         113       0.00      0.00      0.00         1\n",
      "         114       0.00      0.00      0.00         1\n",
      "         115       0.00      0.00      0.00         1\n",
      "         116       0.00      0.00      0.00         2\n",
      "         117       0.00      0.00      0.00         1\n",
      "         118       0.00      0.00      0.00         1\n",
      "         119       0.00      0.00      0.00         1\n",
      "         120       0.00      0.00      0.00         1\n",
      "         121       0.00      0.00      0.00         2\n",
      "         122       0.00      0.00      0.00         1\n",
      "         123       0.00      0.00      0.00         1\n",
      "         124       0.00      0.00      0.00         1\n",
      "         125       0.00      0.00      0.00         1\n",
      "         126       0.00      0.00      0.00         1\n",
      "         127       0.00      0.00      0.00         1\n",
      "         128       0.00      0.00      0.00         1\n",
      "         129       0.00      0.00      0.00         2\n",
      "         130       0.00      0.00      0.00         2\n",
      "         131       0.00      0.00      0.00         2\n",
      "         132       0.00      0.00      0.00         3\n",
      "         133       0.00      0.00      0.00         1\n",
      "         134       0.00      0.00      0.00         1\n",
      "         135       0.00      0.00      0.00         2\n",
      "         136       0.00      0.00      0.00         1\n",
      "         137       0.00      0.00      0.00         1\n",
      "         138       0.00      0.00      0.00         1\n",
      "         139       0.00      0.00      0.00         1\n",
      "         140       0.00      0.00      0.00         1\n",
      "         141       0.00      0.00      0.00         1\n",
      "         142       0.00      0.00      0.00         1\n",
      "         143       0.00      0.00      0.00         1\n",
      "         144       0.00      0.00      0.00         1\n",
      "         145       0.00      0.00      0.00         1\n",
      "         146       0.00      0.00      0.00         1\n",
      "         147       0.00      0.00      0.00         1\n",
      "         148       0.00      0.00      0.00         1\n",
      "         149       0.00      0.00      0.00         1\n",
      "         150       0.00      0.00      0.00         2\n",
      "         151       0.00      0.00      0.00         1\n",
      "         152       0.00      0.00      0.00         2\n",
      "         153       0.00      0.00      0.00         1\n",
      "         154       0.00      0.00      0.00         1\n",
      "         155       0.00      0.00      0.00         1\n",
      "         156       1.00      1.00      1.00         1\n",
      "         157       0.00      0.00      0.00         1\n",
      "         158       0.00      0.00      0.00         2\n",
      "         159       0.00      0.00      0.00         1\n",
      "         160       0.00      0.00      0.00         1\n",
      "         161       0.00      0.00      0.00         2\n",
      "         162       0.00      0.00      0.00         1\n",
      "         163       0.00      0.00      0.00         1\n",
      "         164       0.00      0.00      0.00         1\n",
      "         165       0.00      0.00      0.00         1\n",
      "         166       0.00      0.00      0.00         1\n",
      "         167       0.00      0.00      0.00         2\n",
      "         168       0.00      0.00      0.00         1\n",
      "         169       0.00      0.00      0.00         1\n",
      "         170       0.00      0.00      0.00         2\n",
      "         171       0.00      0.00      0.00         1\n",
      "         172       0.00      0.00      0.00         1\n",
      "         173       0.00      0.00      0.00         1\n",
      "         174       0.00      0.00      0.00         1\n",
      "         175       0.00      0.00      0.00         2\n",
      "         176       0.00      0.00      0.00         1\n",
      "         177       0.00      0.00      0.00         1\n",
      "         178       0.00      0.00      0.00         1\n",
      "         179       0.00      0.00      0.00         1\n",
      "         180       0.00      0.00      0.00         2\n",
      "         181       0.00      0.00      0.00         1\n",
      "         182       0.00      0.00      0.00         1\n",
      "         183       0.00      0.00      0.00         1\n",
      "         184       0.00      0.00      0.00         1\n",
      "         185       0.00      0.00      0.00         1\n",
      "         186       0.00      0.00      0.00         1\n",
      "         187       0.00      0.00      0.00         1\n",
      "         188       0.00      0.00      0.00         2\n",
      "         189       0.00      0.00      0.00         2\n",
      "         190       0.00      0.00      0.00         2\n",
      "         191       0.00      0.00      0.00         1\n",
      "         192       0.00      0.00      0.00         2\n",
      "         193       0.00      0.00      0.00         1\n",
      "         194       0.00      0.00      0.00         1\n",
      "         195       0.00      0.00      0.00         1\n",
      "         196       0.00      0.00      0.00         1\n",
      "         197       0.00      0.00      0.00         1\n",
      "         198       0.00      0.00      0.00         1\n",
      "         199       0.00      0.00      0.00         1\n",
      "         200       0.00      0.00      0.00         1\n",
      "         201       0.00      0.00      0.00         1\n",
      "         202       0.00      0.00      0.00         1\n",
      "         203       0.00      0.00      0.00         2\n",
      "         204       0.00      0.00      0.00         2\n",
      "         205       0.00      0.00      0.00         1\n",
      "         206       0.00      0.00      0.00         1\n",
      "         207       1.00      1.00      1.00         1\n",
      "         208       0.00      0.00      0.00         2\n",
      "         209       0.00      0.00      0.00         1\n",
      "         210       0.00      0.00      0.00         1\n",
      "         211       0.00      0.00      0.00         2\n",
      "         212       0.00      0.00      0.00         2\n",
      "         213       0.00      0.00      0.00         1\n",
      "         214       0.00      0.00      0.00         2\n",
      "         215       0.00      0.00      0.00         2\n",
      "         216       0.00      0.00      0.00         1\n",
      "         217       0.00      0.00      0.00         1\n",
      "         218       0.00      0.00      0.00         1\n",
      "         219       0.00      0.00      0.00         2\n",
      "         220       0.00      0.00      0.00         1\n",
      "         221       0.00      0.00      0.00         1\n",
      "         222       0.00      0.00      0.00         1\n",
      "         223       0.00      0.00      0.00         1\n",
      "         224       0.00      0.00      0.00         2\n",
      "         225       0.00      0.00      0.00         2\n",
      "         226       0.00      0.00      0.00         1\n",
      "         227       0.00      0.00      0.00         1\n",
      "         228       0.00      0.00      0.00         1\n",
      "         229       0.00      0.00      0.00         1\n",
      "         230       0.00      0.00      0.00         1\n",
      "         231       0.00      0.00      0.00         1\n",
      "         232       0.00      0.00      0.00         2\n",
      "         233       0.50      1.00      0.67         1\n",
      "         234       0.00      0.00      0.00         2\n",
      "         235       0.00      0.00      0.00         1\n",
      "         236       0.00      0.00      0.00         1\n",
      "         237       0.25      1.00      0.40         1\n",
      "         238       0.00      0.00      0.00         1\n",
      "         239       0.00      0.00      0.00         2\n",
      "         240       0.00      0.00      0.00         1\n",
      "         241       0.00      0.00      0.00         1\n",
      "         242       0.00      0.00      0.00         1\n",
      "         243       0.00      0.00      0.00         2\n",
      "         244       0.00      0.00      0.00         1\n",
      "         245       0.00      0.00      0.00         1\n",
      "         246       0.00      0.00      0.00         2\n",
      "         247       0.14      1.00      0.25         1\n",
      "         248       1.00      1.00      1.00         1\n",
      "         249       0.00      0.00      0.00         1\n",
      "         250       0.00      0.00      0.00         2\n",
      "         251       0.00      0.00      0.00         1\n",
      "         252       0.00      0.00      0.00         1\n",
      "         253       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.04       319\n",
      "   macro avg       0.03      0.05      0.04       319\n",
      "weighted avg       0.03      0.04      0.03       319\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "HHI = data_all[\"HHI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"HHI\"]\n",
    "target_names = [HHI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"HHI\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9717868338557993"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9184952978056427"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.21425193866802192, 'PovertyRate'),\n",
       " (0.2013026594009392, 'Population'),\n",
       " (0.16272836167649388, 'year_x'),\n",
       " (0.043090848112651826, 'State'),\n",
       " (0.04075452092572989, 'state_id'),\n",
       " (0.040392320439636774, 'beneficiaries_part_b'),\n",
       " (0.03841466198531591, 'average_diabetic_enrollees_eye_exam'),\n",
       " (0.03691764223129977, 'diabetic_enrollees_age_65_to_75'),\n",
       " (0.03291177696101026, 'one_ambulatory_visit'),\n",
       " (0.0322203165766288, 'average_female_age_67_to_69_mammogram'),\n",
       " (0.030826215850074237, 'average_diabetic_enrollees_blood_lipids_test'),\n",
       " (0.030403117975833897, 'average_female_enrollees_age_67_to_69'),\n",
       " (0.027112576136348626, 'average_diabetic_enrollees_hemoglobin_a1c_test'),\n",
       " (0.026377064933637284, 'beneficiaries_part_a_eligible'),\n",
       " (0.018042308263381428,\n",
       "  'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees'),\n",
       " (0.017105890089835922, 'leg_amputations_per_1000_enrollees'),\n",
       " (0.007147779773160423, 'year_y')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune Model Parameters using GridSearch (not working)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid selection test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data[\"HHI\"]\n",
    "target_names = [\"negative\", \"positive\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10],\n",
    "              'gamma': [0.0001, 0.001, 0.01]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List the best parameters for this dataset\n",
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions with the hypertuned model\n",
    "predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Test Acc: %.3f' % grid.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, predictions,\n",
    "                            target_names=[\"blue\", \"red\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid selection test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the SVC Model. Can modify parameters to get the best score\n",
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model using the grid search estimator. \n",
    "# This will take the SVC model and try each combination of parameters\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid selection test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'C': [1, 5, 10, 50],\n",
    "              'gamma': [0.0001, 0.0005, 0.001, 0.005]}\n",
    "grid = GridSearchCV(model, param_grid, verbose=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\model_selection\\_split.py:672: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), UserWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.047, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.052, total=   0.5s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.8s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................... C=1, gamma=0.0001, score=0.058, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.042, total=   0.4s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0001, score=0.084, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.047, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.052, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.058, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.042, total=   0.5s\n",
      "[CV] C=1, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=1, gamma=0.0005, score=0.084, total=   0.6s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.047, total=   0.5s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.052, total=   0.5s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.058, total=   0.5s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.042, total=   0.5s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] .................... C=1, gamma=0.001, score=0.084, total=   0.5s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.047, total=   0.5s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.052, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.058, total=   0.4s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.042, total=   0.5s\n",
      "[CV] C=1, gamma=0.005 ................................................\n",
      "[CV] .................... C=1, gamma=0.005, score=0.084, total=   0.5s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.078, total=   0.6s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.115, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.084, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.079, total=   0.4s\n",
      "[CV] C=5, gamma=0.0001 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0001, score=0.141, total=   0.4s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.078, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.115, total=   0.6s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.084, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.079, total=   0.5s\n",
      "[CV] C=5, gamma=0.0005 ...............................................\n",
      "[CV] ................... C=5, gamma=0.0005, score=0.141, total=   0.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.078, total=   0.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.115, total=   0.5s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.084, total=   0.4s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.079, total=   0.4s\n",
      "[CV] C=5, gamma=0.001 ................................................\n",
      "[CV] .................... C=5, gamma=0.001, score=0.141, total=   0.5s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.078, total=   0.4s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.115, total=   0.5s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.084, total=   0.5s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.079, total=   0.5s\n",
      "[CV] C=5, gamma=0.005 ................................................\n",
      "[CV] .................... C=5, gamma=0.005, score=0.141, total=   0.6s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.104, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.168, total=   0.6s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.131, total=   0.5s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.136, total=   0.4s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0001, score=0.157, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.104, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.168, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.131, total=   0.5s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.136, total=   0.4s\n",
      "[CV] C=10, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=10, gamma=0.0005, score=0.157, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.104, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.168, total=   0.6s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.131, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.136, total=   0.4s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................... C=10, gamma=0.001, score=0.157, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.104, total=   0.5s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.168, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.131, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.136, total=   0.4s\n",
      "[CV] C=10, gamma=0.005 ...............................................\n",
      "[CV] ................... C=10, gamma=0.005, score=0.157, total=   0.4s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .................. C=50, gamma=0.0001, score=0.281, total=   0.4s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.372, total=   0.4s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.330, total=   0.5s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.319, total=   0.4s\n",
      "[CV] C=50, gamma=0.0001 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0001, score=0.351, total=   0.6s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.281, total=   0.4s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.372, total=   0.6s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.330, total=   0.4s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.319, total=   0.4s\n",
      "[CV] C=50, gamma=0.0005 ..............................................\n",
      "[CV] .................. C=50, gamma=0.0005, score=0.351, total=   0.4s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.281, total=   0.6s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.372, total=   0.4s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.330, total=   0.4s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.319, total=   0.7s\n",
      "[CV] C=50, gamma=0.001 ...............................................\n",
      "[CV] ................... C=50, gamma=0.001, score=0.351, total=   0.6s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.281, total=   0.4s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.372, total=   0.4s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.330, total=   0.4s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.319, total=   0.5s\n",
      "[CV] C=50, gamma=0.005 ...............................................\n",
      "[CV] ................... C=50, gamma=0.005, score=0.351, total=   0.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:   37.8s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(kernel='linear'),\n",
       "             param_grid={'C': [1, 5, 10, 50],\n",
       "                         'gamma': [0.0001, 0.0005, 0.001, 0.005]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model with GridSearch\n",
    "grid.fit(X_train_scaled, encoded_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'gamma': 0.0001}\n",
      "0.3305955497382199\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['svm_model.sav']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model\n",
    "\n",
    "import joblib\n",
    "filename = 'svm_model.sav'\n",
    "joblib.dump(model, filename)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
