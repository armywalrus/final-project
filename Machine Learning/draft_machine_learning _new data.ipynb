{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial data read-in/prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn \n",
    "\n",
    "# !pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update tensorflow\n",
    "\n",
    "# !pip install tensorflow --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# Import dependencies\n",
    "\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler,StandardScaler\n",
    "from sklearn import tree\n",
    "from sklearn import preprocessing\n",
    "# from sklearn.linear_model import Linear Regression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import asarray\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>year</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2011</td>\n",
       "      <td>700703</td>\n",
       "      <td>69014</td>\n",
       "      <td>9.292239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2011</td>\n",
       "      <td>6337373</td>\n",
       "      <td>50752</td>\n",
       "      <td>15.835820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2011</td>\n",
       "      <td>2895928</td>\n",
       "      <td>40149</td>\n",
       "      <td>17.846507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2011</td>\n",
       "      <td>36969200</td>\n",
       "      <td>61632</td>\n",
       "      <td>14.096818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Name  year  Population    HHI  PovertyRate\n",
       "0     Alabama  2011     4747424  42934    17.133186\n",
       "1      Alaska  2011      700703  69014     9.292239\n",
       "2     Arizona  2011     6337373  50752    15.835820\n",
       "3    Arkansas  2011     2895928  40149    17.846507\n",
       "4  California  2011    36969200  61632    14.096818"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the census csv into a pandas DataFrame\n",
    "\n",
    "census = pd.read_csv('../Resources/Tableau_clean/census_all.csv')\n",
    "census.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>year</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>2011</td>\n",
       "      <td>700703</td>\n",
       "      <td>69014</td>\n",
       "      <td>9.292239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>2011</td>\n",
       "      <td>6337373</td>\n",
       "      <td>50752</td>\n",
       "      <td>15.835820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>2011</td>\n",
       "      <td>2895928</td>\n",
       "      <td>40149</td>\n",
       "      <td>17.846507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>2011</td>\n",
       "      <td>36969200</td>\n",
       "      <td>61632</td>\n",
       "      <td>14.096818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>2015</td>\n",
       "      <td>8256630</td>\n",
       "      <td>65015</td>\n",
       "      <td>11.164628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Washington</td>\n",
       "      <td>2015</td>\n",
       "      <td>6985464</td>\n",
       "      <td>61062</td>\n",
       "      <td>13.005750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>2015</td>\n",
       "      <td>1851420</td>\n",
       "      <td>41751</td>\n",
       "      <td>17.466809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>2015</td>\n",
       "      <td>5742117</td>\n",
       "      <td>53357</td>\n",
       "      <td>12.614651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_name  year  Population    HHI  PovertyRate\n",
       "0          Alabama  2011     4747424  42934    17.133186\n",
       "1           Alaska  2011      700703  69014     9.292239\n",
       "2          Arizona  2011     6337373  50752    15.835820\n",
       "3         Arkansas  2011     2895928  40149    17.846507\n",
       "4       California  2011    36969200  61632    14.096818\n",
       "..             ...   ...         ...    ...          ...\n",
       "250       Virginia  2015     8256630  65015    11.164628\n",
       "251     Washington  2015     6985464  61062    13.005750\n",
       "252  West Virginia  2015     1851420  41751    17.466809\n",
       "253      Wisconsin  2015     5742117  53357    12.614651\n",
       "254        Wyoming  2015      579679  58840    11.212240\n",
       "\n",
       "[255 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename State column for joining\n",
    "\n",
    "census = census.rename(columns={'Name': 'state_name'})\n",
    "census"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_id</th>\n",
       "      <th>year</th>\n",
       "      <th>state_name</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>average_diabetic_enrollees_hemoglobin_a1c_test</th>\n",
       "      <th>average_diabetic_enrollees_eye_exam</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "      <th>average_female_enrollees_age_67_to_69</th>\n",
       "      <th>average_female_age_67_to_69_mammogram</th>\n",
       "      <th>beneficiaries_part_a_eligible</th>\n",
       "      <th>leg_amputations_per_1000_enrollees</th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>63.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>42267.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>501422.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Alaska</td>\n",
       "      <td>49648.0</td>\n",
       "      <td>70.9</td>\n",
       "      <td>5449.0</td>\n",
       "      <td>74.5</td>\n",
       "      <td>55.8</td>\n",
       "      <td>66.9</td>\n",
       "      <td>5151.0</td>\n",
       "      <td>55.3</td>\n",
       "      <td>54928.0</td>\n",
       "      <td>0.81</td>\n",
       "      <td>53.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>465298.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>50991.0</td>\n",
       "      <td>78.5</td>\n",
       "      <td>66.1</td>\n",
       "      <td>75.8</td>\n",
       "      <td>43614.0</td>\n",
       "      <td>64.3</td>\n",
       "      <td>501103.0</td>\n",
       "      <td>0.57</td>\n",
       "      <td>51.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>Arkansas</td>\n",
       "      <td>327939.0</td>\n",
       "      <td>80.7</td>\n",
       "      <td>40202.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>66.1</td>\n",
       "      <td>76.2</td>\n",
       "      <td>29290.0</td>\n",
       "      <td>58.3</td>\n",
       "      <td>345431.0</td>\n",
       "      <td>0.85</td>\n",
       "      <td>77.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2011</td>\n",
       "      <td>California</td>\n",
       "      <td>2238140.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>243999.0</td>\n",
       "      <td>80.6</td>\n",
       "      <td>64.1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>190971.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>2378472.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>49.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>49.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>832699.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>98165.0</td>\n",
       "      <td>87.6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>83135.0</td>\n",
       "      <td>64.5</td>\n",
       "      <td>703266.0</td>\n",
       "      <td>0.53</td>\n",
       "      <td>42.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>50.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Washington</td>\n",
       "      <td>610922.0</td>\n",
       "      <td>78.5</td>\n",
       "      <td>56474.0</td>\n",
       "      <td>86.6</td>\n",
       "      <td>67.7</td>\n",
       "      <td>76.3</td>\n",
       "      <td>56238.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>510796.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>32.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>51.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>206961.0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>29239.0</td>\n",
       "      <td>84.7</td>\n",
       "      <td>59.9</td>\n",
       "      <td>78.2</td>\n",
       "      <td>20777.0</td>\n",
       "      <td>59.1</td>\n",
       "      <td>171837.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>52.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>474364.0</td>\n",
       "      <td>79.8</td>\n",
       "      <td>46596.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>69.7</td>\n",
       "      <td>81.6</td>\n",
       "      <td>44595.0</td>\n",
       "      <td>71.9</td>\n",
       "      <td>418646.0</td>\n",
       "      <td>0.65</td>\n",
       "      <td>45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>53.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.5</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58899.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state_id  year     state_name  beneficiaries_part_b  \\\n",
       "0         1.0  2011        Alabama              478784.0   \n",
       "1         2.0  2011         Alaska               49648.0   \n",
       "2         3.0  2011        Arizona              465298.0   \n",
       "3         4.0  2011       Arkansas              327939.0   \n",
       "4         5.0  2011     California             2238140.0   \n",
       "..        ...   ...            ...                   ...   \n",
       "250      49.0  2015       Virginia              832699.0   \n",
       "251      50.0  2015     Washington              610922.0   \n",
       "252      51.0  2015  West Virginia              206961.0   \n",
       "253      52.0  2015      Wisconsin              474364.0   \n",
       "254      53.0  2015        Wyoming               72959.0   \n",
       "\n",
       "     one_ambulatory_visit  diabetic_enrollees_age_65_to_75  \\\n",
       "0                    82.5                          69691.0   \n",
       "1                    70.9                           5449.0   \n",
       "2                    78.2                          50991.0   \n",
       "3                    80.7                          40202.0   \n",
       "4                    72.7                         243999.0   \n",
       "..                    ...                              ...   \n",
       "250                  83.3                          98165.0   \n",
       "251                  78.5                          56474.0   \n",
       "252                  80.8                          29239.0   \n",
       "253                  79.8                          46596.0   \n",
       "254                  72.7                           6146.0   \n",
       "\n",
       "     average_diabetic_enrollees_hemoglobin_a1c_test  \\\n",
       "0                                              83.9   \n",
       "1                                              74.5   \n",
       "2                                              78.5   \n",
       "3                                              82.5   \n",
       "4                                              80.6   \n",
       "..                                              ...   \n",
       "250                                            87.6   \n",
       "251                                            86.6   \n",
       "252                                            84.7   \n",
       "253                                            91.0   \n",
       "254                                            78.2   \n",
       "\n",
       "     average_diabetic_enrollees_eye_exam  \\\n",
       "0                                   63.3   \n",
       "1                                   55.8   \n",
       "2                                   66.1   \n",
       "3                                   66.1   \n",
       "4                                   64.1   \n",
       "..                                   ...   \n",
       "250                                 70.0   \n",
       "251                                 67.7   \n",
       "252                                 59.9   \n",
       "253                                 69.7   \n",
       "254                                 62.8   \n",
       "\n",
       "     average_diabetic_enrollees_blood_lipids_test  \\\n",
       "0                                            80.3   \n",
       "1                                            66.9   \n",
       "2                                            75.8   \n",
       "3                                            76.2   \n",
       "4                                            78.0   \n",
       "..                                            ...   \n",
       "250                                          82.0   \n",
       "251                                          76.3   \n",
       "252                                          78.2   \n",
       "253                                          81.6   \n",
       "254                                          59.5   \n",
       "\n",
       "     average_female_enrollees_age_67_to_69  \\\n",
       "0                                  42267.0   \n",
       "1                                   5151.0   \n",
       "2                                  43614.0   \n",
       "3                                  29290.0   \n",
       "4                                 190971.0   \n",
       "..                                     ...   \n",
       "250                                83135.0   \n",
       "251                                56238.0   \n",
       "252                                20777.0   \n",
       "253                                44595.0   \n",
       "254                                 7201.0   \n",
       "\n",
       "     average_female_age_67_to_69_mammogram  beneficiaries_part_a_eligible  \\\n",
       "0                                     62.8                       501422.0   \n",
       "1                                     55.3                        54928.0   \n",
       "2                                     64.3                       501103.0   \n",
       "3                                     58.3                       345431.0   \n",
       "4                                     59.0                      2378472.0   \n",
       "..                                     ...                            ...   \n",
       "250                                   64.5                       703266.0   \n",
       "251                                   60.0                       510796.0   \n",
       "252                                   59.1                       171837.0   \n",
       "253                                   71.9                       418646.0   \n",
       "254                                   56.0                        58899.0   \n",
       "\n",
       "     leg_amputations_per_1000_enrollees  \\\n",
       "0                                  0.99   \n",
       "1                                  0.81   \n",
       "2                                  0.57   \n",
       "3                                  0.85   \n",
       "4                                  0.63   \n",
       "..                                  ...   \n",
       "250                                0.53   \n",
       "251                                0.46   \n",
       "252                                0.90   \n",
       "253                                0.65   \n",
       "254                                0.39   \n",
       "\n",
       "     discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \n",
       "0                                                 76.4                   \n",
       "1                                                 53.1                   \n",
       "2                                                 51.4                   \n",
       "3                                                 77.0                   \n",
       "4                                                 49.9                   \n",
       "..                                                 ...                   \n",
       "250                                               42.8                   \n",
       "251                                               32.7                   \n",
       "252                                               75.0                   \n",
       "253                                               45.0                   \n",
       "254                                               43.1                   \n",
       "\n",
       "[255 rows x 14 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the medicare csv into a pandas DataFrame\n",
    "\n",
    "medicare = pd.read_csv('../Resources/Tableau_clean/medicare_all.csv')\n",
    "medicare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_id',\n",
       " 'year',\n",
       " 'state_name',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names for joining\n",
    "\n",
    "list(medicare.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>year</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "      <th>state_id</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>average_diabetic_enrollees_hemoglobin_a1c_test</th>\n",
       "      <th>average_diabetic_enrollees_eye_exam</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "      <th>average_female_enrollees_age_67_to_69</th>\n",
       "      <th>average_female_age_67_to_69_mammogram</th>\n",
       "      <th>beneficiaries_part_a_eligible</th>\n",
       "      <th>leg_amputations_per_1000_enrollees</th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>63.3</td>\n",
       "      <td>80.3</td>\n",
       "      <td>42267.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>501422.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>76.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>492195.0</td>\n",
       "      <td>82.8</td>\n",
       "      <td>72392.0</td>\n",
       "      <td>84.2</td>\n",
       "      <td>63.2</td>\n",
       "      <td>80.7</td>\n",
       "      <td>42535.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>517526.0</td>\n",
       "      <td>0.90</td>\n",
       "      <td>71.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>498123.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>74492.0</td>\n",
       "      <td>84.9</td>\n",
       "      <td>63.8</td>\n",
       "      <td>81.8</td>\n",
       "      <td>44502.0</td>\n",
       "      <td>62.7</td>\n",
       "      <td>525015.0</td>\n",
       "      <td>0.87</td>\n",
       "      <td>65.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>506023.0</td>\n",
       "      <td>83.2</td>\n",
       "      <td>76238.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>63.7</td>\n",
       "      <td>81.1</td>\n",
       "      <td>48751.0</td>\n",
       "      <td>62.8</td>\n",
       "      <td>534296.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>61.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>510586.0</td>\n",
       "      <td>83.3</td>\n",
       "      <td>68202.0</td>\n",
       "      <td>86.1</td>\n",
       "      <td>64.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>52169.0</td>\n",
       "      <td>63.1</td>\n",
       "      <td>404987.0</td>\n",
       "      <td>0.79</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>61634.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>5750.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>64.7</td>\n",
       "      <td>58.7</td>\n",
       "      <td>5517.0</td>\n",
       "      <td>57.4</td>\n",
       "      <td>65932.0</td>\n",
       "      <td>0.62</td>\n",
       "      <td>55.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>64431.0</td>\n",
       "      <td>73.3</td>\n",
       "      <td>6017.0</td>\n",
       "      <td>74.7</td>\n",
       "      <td>63.8</td>\n",
       "      <td>59.4</td>\n",
       "      <td>5519.0</td>\n",
       "      <td>57.9</td>\n",
       "      <td>69056.0</td>\n",
       "      <td>0.46</td>\n",
       "      <td>52.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>68066.0</td>\n",
       "      <td>74.6</td>\n",
       "      <td>6475.0</td>\n",
       "      <td>75.4</td>\n",
       "      <td>62.7</td>\n",
       "      <td>60.2</td>\n",
       "      <td>5844.0</td>\n",
       "      <td>57.1</td>\n",
       "      <td>73043.0</td>\n",
       "      <td>0.67</td>\n",
       "      <td>47.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>70457.0</td>\n",
       "      <td>73.8</td>\n",
       "      <td>6832.0</td>\n",
       "      <td>76.7</td>\n",
       "      <td>63.2</td>\n",
       "      <td>59.7</td>\n",
       "      <td>6498.0</td>\n",
       "      <td>56.3</td>\n",
       "      <td>75824.0</td>\n",
       "      <td>0.38</td>\n",
       "      <td>46.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>62.8</td>\n",
       "      <td>59.5</td>\n",
       "      <td>7201.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>58899.0</td>\n",
       "      <td>0.39</td>\n",
       "      <td>43.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1275 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state_name  year  Population    HHI  PovertyRate  state_id  \\\n",
       "0       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "1       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "2       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "3       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "4       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "...         ...   ...         ...    ...          ...       ...   \n",
       "1270    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "1271    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "1272    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "1273    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "1274    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "\n",
       "      beneficiaries_part_b  one_ambulatory_visit  \\\n",
       "0                 478784.0                  82.5   \n",
       "1                 492195.0                  82.8   \n",
       "2                 498123.0                  83.3   \n",
       "3                 506023.0                  83.2   \n",
       "4                 510586.0                  83.3   \n",
       "...                    ...                   ...   \n",
       "1270               61634.0                  73.0   \n",
       "1271               64431.0                  73.3   \n",
       "1272               68066.0                  74.6   \n",
       "1273               70457.0                  73.8   \n",
       "1274               72959.0                  72.7   \n",
       "\n",
       "      diabetic_enrollees_age_65_to_75  \\\n",
       "0                             69691.0   \n",
       "1                             72392.0   \n",
       "2                             74492.0   \n",
       "3                             76238.0   \n",
       "4                             68202.0   \n",
       "...                               ...   \n",
       "1270                           5750.0   \n",
       "1271                           6017.0   \n",
       "1272                           6475.0   \n",
       "1273                           6832.0   \n",
       "1274                           6146.0   \n",
       "\n",
       "      average_diabetic_enrollees_hemoglobin_a1c_test  \\\n",
       "0                                               83.9   \n",
       "1                                               84.2   \n",
       "2                                               84.9   \n",
       "3                                               85.0   \n",
       "4                                               86.1   \n",
       "...                                              ...   \n",
       "1270                                            74.7   \n",
       "1271                                            74.7   \n",
       "1272                                            75.4   \n",
       "1273                                            76.7   \n",
       "1274                                            78.2   \n",
       "\n",
       "      average_diabetic_enrollees_eye_exam  \\\n",
       "0                                    63.3   \n",
       "1                                    63.2   \n",
       "2                                    63.8   \n",
       "3                                    63.7   \n",
       "4                                    64.0   \n",
       "...                                   ...   \n",
       "1270                                 64.7   \n",
       "1271                                 63.8   \n",
       "1272                                 62.7   \n",
       "1273                                 63.2   \n",
       "1274                                 62.8   \n",
       "\n",
       "      average_diabetic_enrollees_blood_lipids_test  \\\n",
       "0                                             80.3   \n",
       "1                                             80.7   \n",
       "2                                             81.8   \n",
       "3                                             81.1   \n",
       "4                                             81.0   \n",
       "...                                            ...   \n",
       "1270                                          58.7   \n",
       "1271                                          59.4   \n",
       "1272                                          60.2   \n",
       "1273                                          59.7   \n",
       "1274                                          59.5   \n",
       "\n",
       "      average_female_enrollees_age_67_to_69  \\\n",
       "0                                   42267.0   \n",
       "1                                   42535.0   \n",
       "2                                   44502.0   \n",
       "3                                   48751.0   \n",
       "4                                   52169.0   \n",
       "...                                     ...   \n",
       "1270                                 5517.0   \n",
       "1271                                 5519.0   \n",
       "1272                                 5844.0   \n",
       "1273                                 6498.0   \n",
       "1274                                 7201.0   \n",
       "\n",
       "      average_female_age_67_to_69_mammogram  beneficiaries_part_a_eligible  \\\n",
       "0                                      62.8                       501422.0   \n",
       "1                                      62.7                       517526.0   \n",
       "2                                      62.7                       525015.0   \n",
       "3                                      62.8                       534296.0   \n",
       "4                                      63.1                       404987.0   \n",
       "...                                     ...                            ...   \n",
       "1270                                   57.4                        65932.0   \n",
       "1271                                   57.9                        69056.0   \n",
       "1272                                   57.1                        73043.0   \n",
       "1273                                   56.3                        75824.0   \n",
       "1274                                   56.0                        58899.0   \n",
       "\n",
       "      leg_amputations_per_1000_enrollees  \\\n",
       "0                                   0.99   \n",
       "1                                   0.90   \n",
       "2                                   0.87   \n",
       "3                                   0.83   \n",
       "4                                   0.79   \n",
       "...                                  ...   \n",
       "1270                                0.62   \n",
       "1271                                0.46   \n",
       "1272                                0.67   \n",
       "1273                                0.38   \n",
       "1274                                0.39   \n",
       "\n",
       "      discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \n",
       "0                                                  76.4                   \n",
       "1                                                  71.5                   \n",
       "2                                                  65.4                   \n",
       "3                                                  61.1                   \n",
       "4                                                  62.0                   \n",
       "...                                                 ...                   \n",
       "1270                                               55.2                   \n",
       "1271                                               52.7                   \n",
       "1272                                               47.9                   \n",
       "1273                                               46.1                   \n",
       "1274                                               43.1                   \n",
       "\n",
       "[1275 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join csvs\n",
    "\n",
    "data = pd.merge(census,\n",
    "                 medicare[['state_id', 'state_name', 'beneficiaries_part_b', 'one_ambulatory_visit', 'diabetic_enrollees_age_65_to_75',\n",
    " 'average_diabetic_enrollees_hemoglobin_a1c_test', 'average_diabetic_enrollees_eye_exam', 'average_diabetic_enrollees_blood_lipids_test',\n",
    " 'average_female_enrollees_age_67_to_69', 'average_female_age_67_to_69_mammogram', 'beneficiaries_part_a_eligible', 'leg_amputations_per_1000_enrollees',\n",
    " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees']],\n",
    "                 on='state_name')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>State</th>\n",
       "      <th>Days_with_AQI</th>\n",
       "      <th>Year</th>\n",
       "      <th>Good_Days</th>\n",
       "      <th>Moderate_Days</th>\n",
       "      <th>Unhealthy_Days</th>\n",
       "      <th>Very_Unhealthy_Days</th>\n",
       "      <th>Hazardous_Days</th>\n",
       "      <th>Days_CO</th>\n",
       "      <th>Days_NO2</th>\n",
       "      <th>Days_Ozone</th>\n",
       "      <th>Days_SO2</th>\n",
       "      <th>Days_PM2_5</th>\n",
       "      <th>Days_PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>248.53</td>\n",
       "      <td>2011</td>\n",
       "      <td>171.79</td>\n",
       "      <td>72.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>158.63</td>\n",
       "      <td>0.16</td>\n",
       "      <td>84.89</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>274.50</td>\n",
       "      <td>2011</td>\n",
       "      <td>235.25</td>\n",
       "      <td>34.88</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176.25</td>\n",
       "      <td>20.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>320.62</td>\n",
       "      <td>2011</td>\n",
       "      <td>177.15</td>\n",
       "      <td>117.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.15</td>\n",
       "      <td>167.15</td>\n",
       "      <td>16.54</td>\n",
       "      <td>27.77</td>\n",
       "      <td>106.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>216.88</td>\n",
       "      <td>2011</td>\n",
       "      <td>154.47</td>\n",
       "      <td>59.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>108.76</td>\n",
       "      <td>14.76</td>\n",
       "      <td>90.35</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>345.65</td>\n",
       "      <td>2011</td>\n",
       "      <td>193.17</td>\n",
       "      <td>120.37</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.91</td>\n",
       "      <td>197.43</td>\n",
       "      <td>0.09</td>\n",
       "      <td>129.24</td>\n",
       "      <td>11.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>261.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>228.14</td>\n",
       "      <td>32.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>35.06</td>\n",
       "      <td>141.26</td>\n",
       "      <td>0.97</td>\n",
       "      <td>73.66</td>\n",
       "      <td>8.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Washington</td>\n",
       "      <td>345.83</td>\n",
       "      <td>2015</td>\n",
       "      <td>292.76</td>\n",
       "      <td>48.14</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>47.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.21</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>280.47</td>\n",
       "      <td>2015</td>\n",
       "      <td>234.07</td>\n",
       "      <td>45.20</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145.53</td>\n",
       "      <td>40.47</td>\n",
       "      <td>81.20</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>291.79</td>\n",
       "      <td>2015</td>\n",
       "      <td>245.86</td>\n",
       "      <td>42.68</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>191.43</td>\n",
       "      <td>14.54</td>\n",
       "      <td>84.86</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>309.42</td>\n",
       "      <td>2015</td>\n",
       "      <td>262.58</td>\n",
       "      <td>45.68</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.58</td>\n",
       "      <td>235.89</td>\n",
       "      <td>0.53</td>\n",
       "      <td>29.32</td>\n",
       "      <td>42.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             State  Days_with_AQI  Year  Good_Days  Moderate_Days  \\\n",
       "0          Alabama         248.53  2011     171.79          72.37   \n",
       "1           Alaska         274.50  2011     235.25          34.88   \n",
       "2          Arizona         320.62  2011     177.15         117.00   \n",
       "3         Arkansas         216.88  2011     154.47          59.18   \n",
       "4       California         345.65  2011     193.17         120.37   \n",
       "..             ...            ...   ...        ...            ...   \n",
       "250       Virginia         261.00  2015     228.14          32.34   \n",
       "251     Washington         345.83  2015     292.76          48.14   \n",
       "252  West Virginia         280.47  2015     234.07          45.20   \n",
       "253      Wisconsin         291.79  2015     245.86          42.68   \n",
       "254        Wyoming         309.42  2015     262.58          45.68   \n",
       "\n",
       "     Unhealthy_Days  Very_Unhealthy_Days  Hazardous_Days  Days_CO  Days_NO2  \\\n",
       "0              0.37                 0.00            0.37     0.11      0.00   \n",
       "1              0.62                 0.12            0.62     2.12      0.00   \n",
       "2              2.38                 1.00            2.38     0.00      3.15   \n",
       "3              0.12                 0.00            0.12     0.00      3.00   \n",
       "4              7.02                 0.37            7.02     0.17      6.91   \n",
       "..              ...                  ...             ...      ...       ...   \n",
       "250            0.00                 0.00            0.00     1.14     35.06   \n",
       "251            1.03                 0.07            1.03     0.00      2.69   \n",
       "252            0.07                 0.00            0.07     0.13      0.00   \n",
       "253            0.07                 0.00            0.07     0.00      0.71   \n",
       "254            0.21                 0.00            0.21     0.05      1.58   \n",
       "\n",
       "     Days_Ozone  Days_SO2  Days_PM2_5  Days_PM10  \n",
       "0        158.63      0.16       84.89       4.74  \n",
       "1         75.62      0.00      176.25      20.50  \n",
       "2        167.15     16.54       27.77     106.00  \n",
       "3        108.76     14.76       90.35       0.00  \n",
       "4        197.43      0.09      129.24      11.81  \n",
       "..          ...       ...         ...        ...  \n",
       "250      141.26      0.97       73.66       8.91  \n",
       "251       47.45      0.00      290.21       5.48  \n",
       "252      145.53     40.47       81.20      13.13  \n",
       "253      191.43     14.54       84.86       0.25  \n",
       "254      235.89      0.53       29.32      42.05  \n",
       "\n",
       "[255 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in Pollution data\n",
    "\n",
    "pollution = pd.read_csv('../Resources/Tableau_clean/pollution_all.csv')\n",
    "pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>Days_with_AQI</th>\n",
       "      <th>Year</th>\n",
       "      <th>Good_Days</th>\n",
       "      <th>Moderate_Days</th>\n",
       "      <th>Unhealthy_Days</th>\n",
       "      <th>Very_Unhealthy_Days</th>\n",
       "      <th>Hazardous_Days</th>\n",
       "      <th>Days_CO</th>\n",
       "      <th>Days_NO2</th>\n",
       "      <th>Days_Ozone</th>\n",
       "      <th>Days_SO2</th>\n",
       "      <th>Days_PM2_5</th>\n",
       "      <th>Days_PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>248.53</td>\n",
       "      <td>2011</td>\n",
       "      <td>171.79</td>\n",
       "      <td>72.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>158.63</td>\n",
       "      <td>0.16</td>\n",
       "      <td>84.89</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alaska</td>\n",
       "      <td>274.50</td>\n",
       "      <td>2011</td>\n",
       "      <td>235.25</td>\n",
       "      <td>34.88</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.62</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>75.62</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176.25</td>\n",
       "      <td>20.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arizona</td>\n",
       "      <td>320.62</td>\n",
       "      <td>2011</td>\n",
       "      <td>177.15</td>\n",
       "      <td>117.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.38</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.15</td>\n",
       "      <td>167.15</td>\n",
       "      <td>16.54</td>\n",
       "      <td>27.77</td>\n",
       "      <td>106.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arkansas</td>\n",
       "      <td>216.88</td>\n",
       "      <td>2011</td>\n",
       "      <td>154.47</td>\n",
       "      <td>59.18</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>108.76</td>\n",
       "      <td>14.76</td>\n",
       "      <td>90.35</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>California</td>\n",
       "      <td>345.65</td>\n",
       "      <td>2011</td>\n",
       "      <td>193.17</td>\n",
       "      <td>120.37</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.17</td>\n",
       "      <td>6.91</td>\n",
       "      <td>197.43</td>\n",
       "      <td>0.09</td>\n",
       "      <td>129.24</td>\n",
       "      <td>11.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>Virginia</td>\n",
       "      <td>261.00</td>\n",
       "      <td>2015</td>\n",
       "      <td>228.14</td>\n",
       "      <td>32.34</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.14</td>\n",
       "      <td>35.06</td>\n",
       "      <td>141.26</td>\n",
       "      <td>0.97</td>\n",
       "      <td>73.66</td>\n",
       "      <td>8.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>Washington</td>\n",
       "      <td>345.83</td>\n",
       "      <td>2015</td>\n",
       "      <td>292.76</td>\n",
       "      <td>48.14</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.69</td>\n",
       "      <td>47.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.21</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>West Virginia</td>\n",
       "      <td>280.47</td>\n",
       "      <td>2015</td>\n",
       "      <td>234.07</td>\n",
       "      <td>45.20</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>145.53</td>\n",
       "      <td>40.47</td>\n",
       "      <td>81.20</td>\n",
       "      <td>13.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>291.79</td>\n",
       "      <td>2015</td>\n",
       "      <td>245.86</td>\n",
       "      <td>42.68</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>191.43</td>\n",
       "      <td>14.54</td>\n",
       "      <td>84.86</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>309.42</td>\n",
       "      <td>2015</td>\n",
       "      <td>262.58</td>\n",
       "      <td>45.68</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.58</td>\n",
       "      <td>235.89</td>\n",
       "      <td>0.53</td>\n",
       "      <td>29.32</td>\n",
       "      <td>42.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>255 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        state_name  Days_with_AQI  Year  Good_Days  Moderate_Days  \\\n",
       "0          Alabama         248.53  2011     171.79          72.37   \n",
       "1           Alaska         274.50  2011     235.25          34.88   \n",
       "2          Arizona         320.62  2011     177.15         117.00   \n",
       "3         Arkansas         216.88  2011     154.47          59.18   \n",
       "4       California         345.65  2011     193.17         120.37   \n",
       "..             ...            ...   ...        ...            ...   \n",
       "250       Virginia         261.00  2015     228.14          32.34   \n",
       "251     Washington         345.83  2015     292.76          48.14   \n",
       "252  West Virginia         280.47  2015     234.07          45.20   \n",
       "253      Wisconsin         291.79  2015     245.86          42.68   \n",
       "254        Wyoming         309.42  2015     262.58          45.68   \n",
       "\n",
       "     Unhealthy_Days  Very_Unhealthy_Days  Hazardous_Days  Days_CO  Days_NO2  \\\n",
       "0              0.37                 0.00            0.37     0.11      0.00   \n",
       "1              0.62                 0.12            0.62     2.12      0.00   \n",
       "2              2.38                 1.00            2.38     0.00      3.15   \n",
       "3              0.12                 0.00            0.12     0.00      3.00   \n",
       "4              7.02                 0.37            7.02     0.17      6.91   \n",
       "..              ...                  ...             ...      ...       ...   \n",
       "250            0.00                 0.00            0.00     1.14     35.06   \n",
       "251            1.03                 0.07            1.03     0.00      2.69   \n",
       "252            0.07                 0.00            0.07     0.13      0.00   \n",
       "253            0.07                 0.00            0.07     0.00      0.71   \n",
       "254            0.21                 0.00            0.21     0.05      1.58   \n",
       "\n",
       "     Days_Ozone  Days_SO2  Days_PM2_5  Days_PM10  \n",
       "0        158.63      0.16       84.89       4.74  \n",
       "1         75.62      0.00      176.25      20.50  \n",
       "2        167.15     16.54       27.77     106.00  \n",
       "3        108.76     14.76       90.35       0.00  \n",
       "4        197.43      0.09      129.24      11.81  \n",
       "..          ...       ...         ...        ...  \n",
       "250      141.26      0.97       73.66       8.91  \n",
       "251       47.45      0.00      290.21       5.48  \n",
       "252      145.53     40.47       81.20      13.13  \n",
       "253      191.43     14.54       84.86       0.25  \n",
       "254      235.89      0.53       29.32      42.05  \n",
       "\n",
       "[255 rows x 14 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename State column for joining\n",
    "\n",
    "pollution = pollution.rename(columns={'State': 'state_name'})\n",
    "pollution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state_name</th>\n",
       "      <th>year</th>\n",
       "      <th>Population</th>\n",
       "      <th>HHI</th>\n",
       "      <th>PovertyRate</th>\n",
       "      <th>state_id</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>one_ambulatory_visit</th>\n",
       "      <th>diabetic_enrollees_age_65_to_75</th>\n",
       "      <th>average_diabetic_enrollees_hemoglobin_a1c_test</th>\n",
       "      <th>...</th>\n",
       "      <th>Moderate_Days</th>\n",
       "      <th>Unhealthy_Days</th>\n",
       "      <th>Very_Unhealthy_Days</th>\n",
       "      <th>Hazardous_Days</th>\n",
       "      <th>Days_CO</th>\n",
       "      <th>Days_NO2</th>\n",
       "      <th>Days_Ozone</th>\n",
       "      <th>Days_SO2</th>\n",
       "      <th>Days_PM2_5</th>\n",
       "      <th>Days_PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>...</td>\n",
       "      <td>72.37</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>158.63</td>\n",
       "      <td>0.16</td>\n",
       "      <td>84.89</td>\n",
       "      <td>4.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>...</td>\n",
       "      <td>58.82</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>174.53</td>\n",
       "      <td>0.41</td>\n",
       "      <td>85.12</td>\n",
       "      <td>3.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>...</td>\n",
       "      <td>40.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>173.17</td>\n",
       "      <td>4.67</td>\n",
       "      <td>84.06</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>...</td>\n",
       "      <td>46.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.39</td>\n",
       "      <td>173.06</td>\n",
       "      <td>0.11</td>\n",
       "      <td>83.61</td>\n",
       "      <td>3.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>2011</td>\n",
       "      <td>4747424</td>\n",
       "      <td>42934</td>\n",
       "      <td>17.133186</td>\n",
       "      <td>1.0</td>\n",
       "      <td>478784.0</td>\n",
       "      <td>82.5</td>\n",
       "      <td>69691.0</td>\n",
       "      <td>83.9</td>\n",
       "      <td>...</td>\n",
       "      <td>68.28</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.61</td>\n",
       "      <td>137.56</td>\n",
       "      <td>0.33</td>\n",
       "      <td>145.56</td>\n",
       "      <td>3.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6245</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>...</td>\n",
       "      <td>60.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.21</td>\n",
       "      <td>3.21</td>\n",
       "      <td>176.32</td>\n",
       "      <td>21.05</td>\n",
       "      <td>30.53</td>\n",
       "      <td>66.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6246</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>...</td>\n",
       "      <td>80.95</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.68</td>\n",
       "      <td>182.21</td>\n",
       "      <td>20.37</td>\n",
       "      <td>27.74</td>\n",
       "      <td>72.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6247</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>...</td>\n",
       "      <td>60.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.83</td>\n",
       "      <td>246.89</td>\n",
       "      <td>3.67</td>\n",
       "      <td>20.39</td>\n",
       "      <td>44.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6248</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>...</td>\n",
       "      <td>43.32</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.11</td>\n",
       "      <td>233.84</td>\n",
       "      <td>2.58</td>\n",
       "      <td>28.42</td>\n",
       "      <td>40.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6249</th>\n",
       "      <td>Wyoming</td>\n",
       "      <td>2015</td>\n",
       "      <td>579679</td>\n",
       "      <td>58840</td>\n",
       "      <td>11.212240</td>\n",
       "      <td>53.0</td>\n",
       "      <td>72959.0</td>\n",
       "      <td>72.7</td>\n",
       "      <td>6146.0</td>\n",
       "      <td>78.2</td>\n",
       "      <td>...</td>\n",
       "      <td>45.68</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.58</td>\n",
       "      <td>235.89</td>\n",
       "      <td>0.53</td>\n",
       "      <td>29.32</td>\n",
       "      <td>42.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6250 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     state_name  year  Population    HHI  PovertyRate  state_id  \\\n",
       "0       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "1       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "2       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "3       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "4       Alabama  2011     4747424  42934    17.133186       1.0   \n",
       "...         ...   ...         ...    ...          ...       ...   \n",
       "6245    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "6246    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "6247    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "6248    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "6249    Wyoming  2015      579679  58840    11.212240      53.0   \n",
       "\n",
       "      beneficiaries_part_b  one_ambulatory_visit  \\\n",
       "0                 478784.0                  82.5   \n",
       "1                 478784.0                  82.5   \n",
       "2                 478784.0                  82.5   \n",
       "3                 478784.0                  82.5   \n",
       "4                 478784.0                  82.5   \n",
       "...                    ...                   ...   \n",
       "6245               72959.0                  72.7   \n",
       "6246               72959.0                  72.7   \n",
       "6247               72959.0                  72.7   \n",
       "6248               72959.0                  72.7   \n",
       "6249               72959.0                  72.7   \n",
       "\n",
       "      diabetic_enrollees_age_65_to_75  \\\n",
       "0                             69691.0   \n",
       "1                             69691.0   \n",
       "2                             69691.0   \n",
       "3                             69691.0   \n",
       "4                             69691.0   \n",
       "...                               ...   \n",
       "6245                           6146.0   \n",
       "6246                           6146.0   \n",
       "6247                           6146.0   \n",
       "6248                           6146.0   \n",
       "6249                           6146.0   \n",
       "\n",
       "      average_diabetic_enrollees_hemoglobin_a1c_test  ...  Moderate_Days  \\\n",
       "0                                               83.9  ...          72.37   \n",
       "1                                               83.9  ...          58.82   \n",
       "2                                               83.9  ...          40.11   \n",
       "3                                               83.9  ...          46.11   \n",
       "4                                               83.9  ...          68.28   \n",
       "...                                              ...  ...            ...   \n",
       "6245                                            78.2  ...          60.16   \n",
       "6246                                            78.2  ...          80.95   \n",
       "6247                                            78.2  ...          60.00   \n",
       "6248                                            78.2  ...          43.32   \n",
       "6249                                            78.2  ...          45.68   \n",
       "\n",
       "      Unhealthy_Days  Very_Unhealthy_Days  Hazardous_Days  Days_CO  Days_NO2  \\\n",
       "0               0.37                 0.00            0.37     0.11      0.00   \n",
       "1               0.24                 0.00            0.24     0.00      0.00   \n",
       "2               0.00                 0.00            0.00     0.00      0.06   \n",
       "3               0.00                 0.00            0.00     0.00      0.39   \n",
       "4               0.17                 0.00            0.17     0.00      0.61   \n",
       "...              ...                  ...             ...      ...       ...   \n",
       "6245            0.26                 0.16            0.26     0.21      3.21   \n",
       "6246            0.63                 0.05            0.63     0.05      5.68   \n",
       "6247            0.06                 0.00            0.06     0.00      3.83   \n",
       "6248            0.32                 0.00            0.32     0.00      5.11   \n",
       "6249            0.21                 0.00            0.21     0.05      1.58   \n",
       "\n",
       "      Days_Ozone  Days_SO2  Days_PM2_5  Days_PM10  \n",
       "0         158.63      0.16       84.89       4.74  \n",
       "1         174.53      0.41       85.12       3.53  \n",
       "2         173.17      4.67       84.06       3.22  \n",
       "3         173.06      0.11       83.61       3.28  \n",
       "4         137.56      0.33      145.56       3.22  \n",
       "...          ...       ...         ...        ...  \n",
       "6245      176.32     21.05       30.53      66.68  \n",
       "6246      182.21     20.37       27.74      72.37  \n",
       "6247      246.89      3.67       20.39      44.22  \n",
       "6248      233.84      2.58       28.42      40.37  \n",
       "6249      235.89      0.53       29.32      42.05  \n",
       "\n",
       "[6250 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join csvs\n",
    "\n",
    "data_all = pd.merge(data, pollution,on='state_name')\n",
    "data_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 1: Comparing Household Income and Population to Medicare Part B Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_name',\n",
       " 'year',\n",
       " 'Population',\n",
       " 'HHI',\n",
       " 'PovertyRate',\n",
       " 'state_id',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees',\n",
       " 'Days_with_AQI',\n",
       " 'Year',\n",
       " 'Good_Days',\n",
       " 'Moderate_Days',\n",
       " 'Unhealthy_Days',\n",
       " 'Very_Unhealthy_Days',\n",
       " 'Hazardous_Days',\n",
       " 'Days_CO',\n",
       " 'Days_NO2',\n",
       " 'Days_Ozone',\n",
       " 'Days_SO2',\n",
       " 'Days_PM2_5',\n",
       " 'Days_PM10']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names \n",
    "\n",
    "list(data_all.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['Population', 'PovertyRate']]\n",
    "y_data = data_all[['beneficiaries_part_b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: \n",
    "<br>\n",
    "Use part of our data to train the algorithm, and part of it to evaluate how well the algorithm does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Population</th>\n",
       "      <th>PovertyRate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>4567968</td>\n",
       "      <td>18.537345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>6028076</td>\n",
       "      <td>15.134033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>6652845</td>\n",
       "      <td>12.273080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>4397353</td>\n",
       "      <td>18.325593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>5785496</td>\n",
       "      <td>9.197414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Population  PovertyRate\n",
       "2186     4567968    18.537345\n",
       "3085     6028076    15.134033\n",
       "5774     6652845    12.273080\n",
       "2119     4397353    18.325593\n",
       "2404     5785496     9.197414"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71 220 129 ... 192  42 196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.1568167271175592\n",
      "Testing Data Score: 0.0927703134996801\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.13      0.33      0.19         6\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.07      0.33      0.11         6\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.00      0.00      0.00         6\n",
      "          10       0.07      0.67      0.12         6\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.00      0.00      0.00         7\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         6\n",
      "          15       0.00      0.00      0.00         7\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         7\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.20      0.33      0.25         6\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00         6\n",
      "          23       0.05      0.50      0.09         6\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.00      0.00      0.00         6\n",
      "          27       0.09      0.33      0.14         6\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00         6\n",
      "          30       0.07      0.50      0.12         6\n",
      "          31       0.00      0.00      0.00         7\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       0.11      0.33      0.16         6\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         6\n",
      "          37       0.00      0.00      0.00         6\n",
      "          38       0.00      0.00      0.00         7\n",
      "          39       0.00      0.00      0.00         6\n",
      "          40       0.06      0.17      0.09         6\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.00      0.00      0.00         7\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.12      0.33      0.18         6\n",
      "          45       0.00      0.00      0.00         7\n",
      "          46       0.00      0.00      0.00         6\n",
      "          47       0.00      0.00      0.00         7\n",
      "          48       0.08      0.67      0.15         6\n",
      "          49       0.00      0.00      0.00         6\n",
      "          50       0.00      0.00      0.00         6\n",
      "          51       0.05      0.33      0.09         6\n",
      "          52       0.00      0.00      0.00         6\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00         6\n",
      "          55       0.00      0.00      0.00         6\n",
      "          56       0.00      0.00      0.00         6\n",
      "          57       0.00      0.00      0.00         7\n",
      "          58       0.00      0.00      0.00         6\n",
      "          59       0.00      0.00      0.00         6\n",
      "          60       0.20      0.17      0.18         6\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.00      0.00      0.00         6\n",
      "          63       0.17      0.50      0.25         6\n",
      "          64       0.11      0.33      0.17         6\n",
      "          65       0.00      0.00      0.00         6\n",
      "          66       0.14      0.17      0.15         6\n",
      "          67       0.00      0.00      0.00         6\n",
      "          68       0.00      0.00      0.00         6\n",
      "          69       0.00      0.00      0.00         7\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00         6\n",
      "          72       0.11      0.67      0.20         6\n",
      "          73       0.00      0.00      0.00         7\n",
      "          74       0.11      0.17      0.13         6\n",
      "          75       0.00      0.00      0.00         6\n",
      "          76       0.08      0.17      0.11         6\n",
      "          77       0.00      0.00      0.00         6\n",
      "          78       0.00      0.00      0.00         6\n",
      "          79       0.00      0.00      0.00         6\n",
      "          80       0.11      0.33      0.16         6\n",
      "          81       0.00      0.00      0.00         7\n",
      "          82       0.00      0.00      0.00         7\n",
      "          83       0.00      0.00      0.00         6\n",
      "          84       0.00      0.00      0.00         7\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.11      0.50      0.18         6\n",
      "          87       0.00      0.00      0.00         6\n",
      "          88       0.07      0.17      0.10         6\n",
      "          89       0.00      0.00      0.00         6\n",
      "          90       0.17      0.17      0.17         6\n",
      "          91       0.00      0.00      0.00         6\n",
      "          92       0.00      0.00      0.00         7\n",
      "          93       0.00      0.00      0.00         7\n",
      "          94       0.00      0.00      0.00         7\n",
      "          95       0.00      0.00      0.00         6\n",
      "          96       0.27      0.50      0.35         6\n",
      "          97       0.00      0.00      0.00         7\n",
      "          98       0.00      0.00      0.00         6\n",
      "          99       0.00      0.00      0.00         6\n",
      "         100       0.00      0.00      0.00         6\n",
      "         101       0.17      0.67      0.27         6\n",
      "         102       0.18      0.50      0.26         6\n",
      "         103       0.00      0.00      0.00         6\n",
      "         104       0.00      0.00      0.00         7\n",
      "         105       0.11      0.33      0.17         6\n",
      "         106       0.00      0.00      0.00         6\n",
      "         107       0.00      0.00      0.00         7\n",
      "         108       0.00      0.00      0.00         7\n",
      "         109       0.00      0.00      0.00         6\n",
      "         110       0.13      1.00      0.23         6\n",
      "         111       0.00      0.00      0.00         7\n",
      "         112       0.00      0.00      0.00         7\n",
      "         113       0.00      0.00      0.00         6\n",
      "         114       0.00      0.00      0.00         6\n",
      "         115       0.00      0.00      0.00         6\n",
      "         116       0.08      0.17      0.11         6\n",
      "         117       0.06      0.17      0.08         6\n",
      "         118       0.15      0.33      0.21         6\n",
      "         119       0.00      0.00      0.00         6\n",
      "         120       0.00      0.00      0.00         6\n",
      "         121       0.00      0.00      0.00         7\n",
      "         122       0.00      0.00      0.00         6\n",
      "         123       0.00      0.00      0.00         6\n",
      "         124       0.20      0.50      0.29         6\n",
      "         125       0.00      0.00      0.00         6\n",
      "         126       0.00      0.00      0.00         7\n",
      "         127       0.00      0.00      0.00         6\n",
      "         128       0.13      0.33      0.19         6\n",
      "         129       0.00      0.00      0.00         6\n",
      "         130       0.00      0.00      0.00         6\n",
      "         131       0.00      0.00      0.00         6\n",
      "         132       0.05      0.17      0.07         6\n",
      "         133       0.03      0.17      0.04         6\n",
      "         134       0.00      0.00      0.00         7\n",
      "         135       0.00      0.00      0.00         7\n",
      "         136       0.00      0.00      0.00         7\n",
      "         137       0.17      0.83      0.28         6\n",
      "         138       0.00      0.00      0.00         6\n",
      "         139       0.00      0.00      0.00         7\n",
      "         140       0.00      0.00      0.00         6\n",
      "         141       0.00      0.00      0.00         6\n",
      "         142       0.00      0.00      0.00         6\n",
      "         143       0.00      0.00      0.00         6\n",
      "         144       0.50      0.50      0.50         6\n",
      "         145       0.33      0.17      0.22         6\n",
      "         146       0.00      0.00      0.00         6\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.00      0.00      0.00         6\n",
      "         149       0.00      0.00      0.00         6\n",
      "         150       0.00      0.00      0.00         6\n",
      "         151       0.00      0.00      0.00         6\n",
      "         152       0.11      0.33      0.16         6\n",
      "         153       0.00      0.00      0.00         7\n",
      "         154       0.00      0.00      0.00         6\n",
      "         155       0.00      0.00      0.00         7\n",
      "         156       0.06      0.33      0.10         6\n",
      "         157       0.06      0.17      0.09         6\n",
      "         158       0.10      0.17      0.12         6\n",
      "         159       0.00      0.00      0.00         6\n",
      "         160       0.00      0.00      0.00         7\n",
      "         161       0.00      0.00      0.00         6\n",
      "         162       0.00      0.00      0.00         6\n",
      "         163       0.18      0.67      0.29         6\n",
      "         164       0.10      0.50      0.17         6\n",
      "         165       0.17      0.17      0.17         6\n",
      "         166       0.00      0.00      0.00         6\n",
      "         167       0.00      0.00      0.00         6\n",
      "         168       0.00      0.00      0.00         7\n",
      "         169       0.05      0.33      0.08         6\n",
      "         170       0.00      0.00      0.00         6\n",
      "         171       0.00      0.00      0.00         7\n",
      "         172       0.00      0.00      0.00         6\n",
      "         173       0.00      0.00      0.00         6\n",
      "         174       0.00      0.00      0.00         6\n",
      "         175       0.00      0.00      0.00         7\n",
      "         176       0.12      0.17      0.14         6\n",
      "         177       0.00      0.00      0.00         6\n",
      "         178       0.00      0.00      0.00         6\n",
      "         179       0.12      0.33      0.17         6\n",
      "         180       0.00      0.00      0.00         6\n",
      "         181       0.00      0.00      0.00         6\n",
      "         182       0.00      0.00      0.00         6\n",
      "         183       0.00      0.00      0.00         6\n",
      "         184       0.00      0.00      0.00         6\n",
      "         185       0.08      0.17      0.11         6\n",
      "         186       0.00      0.00      0.00         7\n",
      "         187       0.00      0.00      0.00         7\n",
      "         188       0.13      0.33      0.19         6\n",
      "         189       0.00      0.00      0.00         7\n",
      "         190       0.00      0.00      0.00         6\n",
      "         191       0.05      0.33      0.09         6\n",
      "         192       0.00      0.00      0.00         6\n",
      "         193       0.00      0.00      0.00         6\n",
      "         194       0.00      0.00      0.00         6\n",
      "         195       0.00      0.00      0.00         6\n",
      "         196       0.13      0.50      0.21         6\n",
      "         197       0.00      0.00      0.00         6\n",
      "         198       0.00      0.00      0.00         6\n",
      "         199       0.00      0.00      0.00         7\n",
      "         200       0.00      0.00      0.00         7\n",
      "         201       0.00      0.00      0.00         6\n",
      "         202       0.00      0.00      0.00         6\n",
      "         203       0.00      0.00      0.00         6\n",
      "         204       0.15      0.67      0.24         6\n",
      "         205       0.00      0.00      0.00         7\n",
      "         206       0.00      0.00      0.00         6\n",
      "         207       0.00      0.00      0.00         7\n",
      "         208       0.00      0.00      0.00         6\n",
      "         209       0.00      0.00      0.00         6\n",
      "         210       0.20      0.33      0.25         6\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.00      0.00      0.00         6\n",
      "         213       0.00      0.00      0.00         6\n",
      "         214       0.00      0.00      0.00         7\n",
      "         215       0.00      0.00      0.00         6\n",
      "         216       0.00      0.00      0.00         6\n",
      "         217       0.00      0.00      0.00         7\n",
      "         218       0.00      0.00      0.00         6\n",
      "         219       0.08      0.17      0.11         6\n",
      "         220       0.00      0.00      0.00         6\n",
      "         221       0.00      0.00      0.00         7\n",
      "         222       0.07      0.33      0.12         6\n",
      "         223       0.07      0.17      0.10         6\n",
      "         224       0.00      0.00      0.00         6\n",
      "         225       0.10      0.33      0.15         6\n",
      "         226       0.00      0.00      0.00         6\n",
      "         227       0.00      0.00      0.00         6\n",
      "         228       0.00      0.00      0.00         7\n",
      "         229       0.00      0.00      0.00         6\n",
      "         230       0.12      0.33      0.18         6\n",
      "         231       0.00      0.00      0.00         6\n",
      "         232       0.10      0.33      0.15         6\n",
      "         233       0.00      0.00      0.00         6\n",
      "         234       0.00      0.00      0.00         6\n",
      "         235       0.00      0.00      0.00         7\n",
      "         236       0.18      1.00      0.30         6\n",
      "         237       0.00      0.00      0.00         7\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       0.15      0.33      0.21         6\n",
      "         240       0.17      0.17      0.17         6\n",
      "         241       0.00      0.00      0.00         7\n",
      "         242       0.00      0.00      0.00         7\n",
      "         243       0.00      0.00      0.00         7\n",
      "         244       0.14      0.17      0.15         6\n",
      "         245       0.00      0.00      0.00         6\n",
      "         246       0.00      0.00      0.00         6\n",
      "         247       0.00      0.00      0.00         6\n",
      "         248       0.17      0.50      0.25         6\n",
      "         249       0.17      0.33      0.22         6\n",
      "\n",
      "    accuracy                           0.09      1563\n",
      "   macro avg       0.03      0.10      0.05      1563\n",
      "weighted avg       0.03      0.09      0.04      1563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 2: New Features\n",
    "## Comparing Income and Particulate Matter to Medicare Part B Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['HHI', 'Days_PM10']]\n",
    "y_data = data_all[['beneficiaries_part_b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHI</th>\n",
       "      <th>Days_PM10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>44874</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>47764</td>\n",
       "      <td>14.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>58890</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>43740</td>\n",
       "      <td>0.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>72999</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HHI  Days_PM10\n",
       "2186  44874       0.45\n",
       "3085  47764      14.09\n",
       "5774  58890       5.48\n",
       "2119  43740       0.86\n",
       "2404  72999       0.06"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71 220 129 ... 192  42 196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.16065713676125454\n",
      "Testing Data Score: 0.08637236084452975\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         6\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       0.10      0.17      0.12         6\n",
      "           4       0.00      0.00      0.00         7\n",
      "           5       0.19      0.67      0.30         6\n",
      "           6       0.00      0.00      0.00         7\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         6\n",
      "           9       0.12      0.50      0.19         6\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.00      0.00      0.00         7\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         6\n",
      "          15       0.00      0.00      0.00         7\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         7\n",
      "          18       0.00      0.00      0.00         6\n",
      "          19       0.06      0.33      0.11         6\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       0.00      0.00      0.00         6\n",
      "          22       0.00      0.00      0.00         6\n",
      "          23       0.12      0.50      0.20         6\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       0.00      0.00      0.00         6\n",
      "          27       0.00      0.00      0.00         6\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00         6\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         7\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       0.00      0.00      0.00         6\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       0.07      0.33      0.11         6\n",
      "          36       0.08      0.17      0.11         6\n",
      "          37       0.04      0.17      0.07         6\n",
      "          38       0.00      0.00      0.00         7\n",
      "          39       0.00      0.00      0.00         6\n",
      "          40       0.10      0.17      0.12         6\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.00      0.00      0.00         7\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00         7\n",
      "          46       0.00      0.00      0.00         6\n",
      "          47       0.00      0.00      0.00         7\n",
      "          48       0.00      0.00      0.00         6\n",
      "          49       0.11      0.17      0.13         6\n",
      "          50       0.11      0.50      0.18         6\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       0.10      0.17      0.12         6\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00         6\n",
      "          55       0.00      0.00      0.00         6\n",
      "          56       0.00      0.00      0.00         6\n",
      "          57       0.00      0.00      0.00         7\n",
      "          58       0.00      0.00      0.00         6\n",
      "          59       0.29      0.33      0.31         6\n",
      "          60       0.00      0.00      0.00         6\n",
      "          61       0.05      0.17      0.08         6\n",
      "          62       0.00      0.00      0.00         6\n",
      "          63       0.00      0.00      0.00         6\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.00      0.00      0.00         6\n",
      "          66       0.00      0.00      0.00         6\n",
      "          67       0.00      0.00      0.00         6\n",
      "          68       0.17      0.67      0.27         6\n",
      "          69       0.00      0.00      0.00         7\n",
      "          70       0.11      0.33      0.16         6\n",
      "          71       0.07      0.17      0.10         6\n",
      "          72       0.12      0.17      0.14         6\n",
      "          73       0.00      0.00      0.00         7\n",
      "          74       0.40      0.33      0.36         6\n",
      "          75       0.00      0.00      0.00         6\n",
      "          76       0.09      0.17      0.12         6\n",
      "          77       0.00      0.00      0.00         6\n",
      "          78       0.00      0.00      0.00         6\n",
      "          79       0.14      0.17      0.15         6\n",
      "          80       0.14      0.17      0.15         6\n",
      "          81       0.00      0.00      0.00         7\n",
      "          82       0.00      0.00      0.00         7\n",
      "          83       0.00      0.00      0.00         6\n",
      "          84       0.00      0.00      0.00         7\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.12      0.17      0.14         6\n",
      "          87       0.00      0.00      0.00         6\n",
      "          88       0.00      0.00      0.00         6\n",
      "          89       0.06      0.17      0.09         6\n",
      "          90       0.08      0.17      0.11         6\n",
      "          91       0.00      0.00      0.00         6\n",
      "          92       0.00      0.00      0.00         7\n",
      "          93       0.00      0.00      0.00         7\n",
      "          94       0.00      0.00      0.00         7\n",
      "          95       0.00      0.00      0.00         6\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         7\n",
      "          98       0.00      0.00      0.00         6\n",
      "          99       0.11      0.67      0.19         6\n",
      "         100       0.14      0.33      0.20         6\n",
      "         101       0.00      0.00      0.00         6\n",
      "         102       0.00      0.00      0.00         6\n",
      "         103       0.00      0.00      0.00         6\n",
      "         104       0.00      0.00      0.00         7\n",
      "         105       0.09      0.17      0.12         6\n",
      "         106       0.00      0.00      0.00         6\n",
      "         107       0.00      0.00      0.00         7\n",
      "         108       0.00      0.00      0.00         7\n",
      "         109       0.22      0.67      0.33         6\n",
      "         110       0.18      1.00      0.30         6\n",
      "         111       0.00      0.00      0.00         7\n",
      "         112       0.00      0.00      0.00         7\n",
      "         113       0.00      0.00      0.00         6\n",
      "         114       0.00      0.00      0.00         6\n",
      "         115       0.00      0.00      0.00         6\n",
      "         116       0.09      0.50      0.15         6\n",
      "         117       0.09      0.17      0.12         6\n",
      "         118       0.10      0.33      0.15         6\n",
      "         119       0.00      0.00      0.00         6\n",
      "         120       0.00      0.00      0.00         6\n",
      "         121       0.00      0.00      0.00         7\n",
      "         122       0.00      0.00      0.00         6\n",
      "         123       0.08      0.17      0.11         6\n",
      "         124       0.18      0.67      0.29         6\n",
      "         125       0.08      0.17      0.11         6\n",
      "         126       0.00      0.00      0.00         7\n",
      "         127       0.00      0.00      0.00         6\n",
      "         128       0.13      0.33      0.19         6\n",
      "         129       0.22      0.33      0.27         6\n",
      "         130       0.00      0.00      0.00         6\n",
      "         131       0.00      0.00      0.00         6\n",
      "         132       0.00      0.00      0.00         6\n",
      "         133       0.12      0.17      0.14         6\n",
      "         134       0.00      0.00      0.00         7\n",
      "         135       0.00      0.00      0.00         7\n",
      "         136       0.00      0.00      0.00         7\n",
      "         137       0.25      0.33      0.29         6\n",
      "         138       0.00      0.00      0.00         6\n",
      "         139       0.00      0.00      0.00         7\n",
      "         140       0.00      0.00      0.00         6\n",
      "         141       0.00      0.00      0.00         6\n",
      "         142       0.00      0.00      0.00         6\n",
      "         143       0.00      0.00      0.00         6\n",
      "         144       0.07      0.33      0.12         6\n",
      "         145       0.00      0.00      0.00         6\n",
      "         146       0.00      0.00      0.00         6\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.10      0.17      0.12         6\n",
      "         149       0.10      0.50      0.16         6\n",
      "         150       0.00      0.00      0.00         6\n",
      "         151       0.15      0.33      0.21         6\n",
      "         152       0.11      0.33      0.16         6\n",
      "         153       0.00      0.00      0.00         7\n",
      "         154       0.00      0.00      0.00         6\n",
      "         155       0.00      0.00      0.00         7\n",
      "         156       0.00      0.00      0.00         6\n",
      "         157       0.00      0.00      0.00         6\n",
      "         158       0.00      0.00      0.00         6\n",
      "         159       0.12      0.33      0.17         6\n",
      "         160       0.00      0.00      0.00         7\n",
      "         161       0.00      0.00      0.00         6\n",
      "         162       0.00      0.00      0.00         6\n",
      "         163       0.14      0.17      0.15         6\n",
      "         164       0.00      0.00      0.00         6\n",
      "         165       0.00      0.00      0.00         6\n",
      "         166       0.00      0.00      0.00         6\n",
      "         167       0.06      0.33      0.10         6\n",
      "         168       0.00      0.00      0.00         7\n",
      "         169       0.00      0.00      0.00         6\n",
      "         170       0.25      0.33      0.29         6\n",
      "         171       0.00      0.00      0.00         7\n",
      "         172       0.05      0.33      0.08         6\n",
      "         173       0.50      0.17      0.25         6\n",
      "         174       0.00      0.00      0.00         6\n",
      "         175       0.00      0.00      0.00         7\n",
      "         176       0.00      0.00      0.00         6\n",
      "         177       0.00      0.00      0.00         6\n",
      "         178       0.00      0.00      0.00         6\n",
      "         179       0.10      0.17      0.12         6\n",
      "         180       0.13      0.33      0.19         6\n",
      "         181       0.00      0.00      0.00         6\n",
      "         182       0.00      0.00      0.00         6\n",
      "         183       0.00      0.00      0.00         6\n",
      "         184       0.07      0.50      0.12         6\n",
      "         185       0.00      0.00      0.00         6\n",
      "         186       0.00      0.00      0.00         7\n",
      "         187       0.00      0.00      0.00         7\n",
      "         188       0.05      0.17      0.08         6\n",
      "         189       0.00      0.00      0.00         7\n",
      "         190       0.00      0.00      0.00         6\n",
      "         191       0.06      0.17      0.08         6\n",
      "         192       0.07      0.17      0.10         6\n",
      "         193       0.00      0.00      0.00         6\n",
      "         194       0.00      0.00      0.00         6\n",
      "         195       0.14      0.33      0.20         6\n",
      "         196       0.14      0.17      0.15         6\n",
      "         197       0.10      0.17      0.12         6\n",
      "         198       0.00      0.00      0.00         6\n",
      "         199       0.00      0.00      0.00         7\n",
      "         200       0.00      0.00      0.00         7\n",
      "         201       0.00      0.00      0.00         6\n",
      "         202       0.00      0.00      0.00         6\n",
      "         203       0.13      0.50      0.21         6\n",
      "         204       0.06      0.17      0.09         6\n",
      "         205       0.00      0.00      0.00         7\n",
      "         206       0.00      0.00      0.00         6\n",
      "         207       0.00      0.00      0.00         7\n",
      "         208       0.00      0.00      0.00         6\n",
      "         209       0.16      0.50      0.24         6\n",
      "         210       0.00      0.00      0.00         6\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.00      0.00      0.00         6\n",
      "         213       0.11      0.17      0.13         6\n",
      "         214       0.00      0.00      0.00         7\n",
      "         215       0.00      0.00      0.00         6\n",
      "         216       0.00      0.00      0.00         6\n",
      "         217       0.00      0.00      0.00         7\n",
      "         218       0.00      0.00      0.00         6\n",
      "         219       0.13      0.50      0.21         6\n",
      "         220       0.00      0.00      0.00         6\n",
      "         221       0.00      0.00      0.00         7\n",
      "         222       0.00      0.00      0.00         6\n",
      "         223       0.00      0.00      0.00         6\n",
      "         224       0.00      0.00      0.00         6\n",
      "         225       0.00      0.00      0.00         6\n",
      "         226       0.04      0.17      0.07         6\n",
      "         227       0.08      0.17      0.11         6\n",
      "         228       0.00      0.00      0.00         7\n",
      "         229       0.00      0.00      0.00         6\n",
      "         230       0.00      0.00      0.00         6\n",
      "         231       0.00      0.00      0.00         6\n",
      "         232       0.00      0.00      0.00         6\n",
      "         233       0.00      0.00      0.00         6\n",
      "         234       0.00      0.00      0.00         6\n",
      "         235       0.00      0.00      0.00         7\n",
      "         236       0.07      0.50      0.12         6\n",
      "         237       0.00      0.00      0.00         7\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       0.11      0.33      0.16         6\n",
      "         240       0.08      0.17      0.11         6\n",
      "         241       0.00      0.00      0.00         7\n",
      "         242       0.00      0.00      0.00         7\n",
      "         243       0.00      0.00      0.00         7\n",
      "         244       0.12      0.17      0.14         6\n",
      "         245       0.00      0.00      0.00         6\n",
      "         246       0.13      0.33      0.19         6\n",
      "         247       0.33      0.17      0.22         6\n",
      "         248       0.10      0.17      0.12         6\n",
      "         249       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.09      1563\n",
      "   macro avg       0.04      0.09      0.05      1563\n",
      "weighted avg       0.04      0.09      0.05      1563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So far, our hypothesis regearding our ability to predict Medicare Part B with pollution and income data appears to be false. We ran feature importance to ascertain which parts of our data would be the strongest features for prpediction of Part B."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"beneficiaries_part_b\"]\n",
    "target_names = data_all[\"beneficiaries_part_b\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"beneficiaries_part_b\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.08971621009957773,\n",
       "  'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees'),\n",
       " (0.08362628205058534, 'one_ambulatory_visit'),\n",
       " (0.0827673285849057, 'average_female_enrollees_age_67_to_69'),\n",
       " (0.08272644503173589, 'average_diabetic_enrollees_blood_lipids_test'),\n",
       " (0.08180427023163049, 'beneficiaries_part_a_eligible'),\n",
       " (0.08084256878299803, 'average_diabetic_enrollees_eye_exam'),\n",
       " (0.08027289276566926, 'diabetic_enrollees_age_65_to_75'),\n",
       " (0.07948283767654866, 'average_diabetic_enrollees_hemoglobin_a1c_test'),\n",
       " (0.07867939797210202, 'average_female_age_67_to_69_mammogram'),\n",
       " (0.07666708376620322, 'leg_amputations_per_1000_enrollees'),\n",
       " (0.026351033070593995, 'Population'),\n",
       " (0.02569187228131522, 'state_id'),\n",
       " (0.020884211797130525, 'HHI'),\n",
       " (0.017115568172923052, 'PovertyRate'),\n",
       " (0.016963118269046683, 'Days_PM10'),\n",
       " (0.013390361346999839, 'Days_PM2_5'),\n",
       " (0.013377225455599348, 'Days_Ozone'),\n",
       " (0.010870155042997452, 'Days_with_AQI'),\n",
       " (0.0106525884774262, 'Days_SO2'),\n",
       " (0.009944699111485768, 'Days_NO2'),\n",
       " (0.005696307498344226, 'Moderate_Days'),\n",
       " (0.005069821106997282, 'Good_Days'),\n",
       " (0.002551647798410968, 'Unhealthy_Days'),\n",
       " (0.002120564972105208, 'Hazardous_Days'),\n",
       " (0.001884988649442098, 'Days_CO'),\n",
       " (0.000328533995123876, 'year'),\n",
       " (0.00030686422762050925, 'Very_Unhealthy_Days'),\n",
       " (0.00021512176448141716, 'Year')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "# shows the features most likely to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 3: New Features\n",
    "## Comparing Ambulatory Discharges and Ambulatory Visits to Medicare Part B Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees', 'average_diabetic_enrollees_blood_lipids_test']]\n",
    "y_data2 = data_all[['beneficiaries_part_b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: \n",
    "<br>\n",
    "Use part of our data to train the algorithm, and part of it to evaluate how well the algorithm does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees</th>\n",
       "      <th>average_diabetic_enrollees_blood_lipids_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2186</th>\n",
       "      <td>73.3</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3085</th>\n",
       "      <td>59.0</td>\n",
       "      <td>80.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5774</th>\n",
       "      <td>32.7</td>\n",
       "      <td>76.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2119</th>\n",
       "      <td>77.0</td>\n",
       "      <td>81.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>60.2</td>\n",
       "      <td>81.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees  \\\n",
       "2186                                               73.3                    \n",
       "3085                                               59.0                    \n",
       "5774                                               32.7                    \n",
       "2119                                               77.0                    \n",
       "2404                                               60.2                    \n",
       "\n",
       "      average_diabetic_enrollees_blood_lipids_test  \n",
       "2186                                          79.0  \n",
       "3085                                          80.0  \n",
       "5774                                          76.3  \n",
       "2119                                          81.3  \n",
       "2404                                          81.7  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 71 220 129 ... 192  42 196]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7964582888841476\n",
      "Testing Data Score: 0.7626359564939219\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00         6\n",
      "           2       1.00      1.00      1.00         7\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       1.00      1.00      1.00         7\n",
      "           5       1.00      1.00      1.00         6\n",
      "           6       1.00      1.00      1.00         7\n",
      "           7       1.00      1.00      1.00         6\n",
      "           8       1.00      1.00      1.00         6\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       0.46      1.00      0.63         6\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.00      0.00      0.00         7\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       1.00      1.00      1.00         6\n",
      "          15       0.00      0.00      0.00         7\n",
      "          16       0.00      0.00      0.00         7\n",
      "          17       0.00      0.00      0.00         7\n",
      "          18       0.46      1.00      0.63         6\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       1.00      1.00      1.00         6\n",
      "          22       1.00      1.00      1.00         6\n",
      "          23       0.46      1.00      0.63         6\n",
      "          24       1.00      1.00      1.00         6\n",
      "          25       0.00      0.00      0.00         7\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       1.00      1.00      1.00         6\n",
      "          28       0.46      1.00      0.63         6\n",
      "          29       1.00      1.00      1.00         6\n",
      "          30       1.00      1.00      1.00         6\n",
      "          31       0.00      0.00      0.00         7\n",
      "          32       1.00      1.00      1.00         6\n",
      "          33       0.46      1.00      0.63         6\n",
      "          34       0.00      0.00      0.00         7\n",
      "          35       1.00      1.00      1.00         6\n",
      "          36       1.00      1.00      1.00         6\n",
      "          37       1.00      1.00      1.00         6\n",
      "          38       1.00      1.00      1.00         7\n",
      "          39       1.00      1.00      1.00         6\n",
      "          40       1.00      1.00      1.00         6\n",
      "          41       0.00      0.00      0.00         7\n",
      "          42       0.00      0.00      0.00         7\n",
      "          43       1.00      1.00      1.00         6\n",
      "          44       1.00      1.00      1.00         6\n",
      "          45       0.00      0.00      0.00         7\n",
      "          46       1.00      1.00      1.00         6\n",
      "          47       0.00      0.00      0.00         7\n",
      "          48       1.00      1.00      1.00         6\n",
      "          49       1.00      1.00      1.00         6\n",
      "          50       1.00      1.00      1.00         6\n",
      "          51       0.46      1.00      0.63         6\n",
      "          52       1.00      1.00      1.00         6\n",
      "          53       1.00      1.00      1.00         6\n",
      "          54       1.00      1.00      1.00         6\n",
      "          55       1.00      1.00      1.00         6\n",
      "          56       1.00      1.00      1.00         6\n",
      "          57       0.00      0.00      0.00         7\n",
      "          58       1.00      1.00      1.00         6\n",
      "          59       1.00      1.00      1.00         6\n",
      "          60       1.00      1.00      1.00         6\n",
      "          61       1.00      1.00      1.00         6\n",
      "          62       1.00      1.00      1.00         6\n",
      "          63       1.00      1.00      1.00         6\n",
      "          64       1.00      1.00      1.00         6\n",
      "          65       1.00      1.00      1.00         6\n",
      "          66       1.00      1.00      1.00         6\n",
      "          67       1.00      1.00      1.00         6\n",
      "          68       1.00      1.00      1.00         6\n",
      "          69       1.00      1.00      1.00         7\n",
      "          70       0.46      1.00      0.63         6\n",
      "          71       1.00      1.00      1.00         6\n",
      "          72       0.30      1.00      0.46         6\n",
      "          73       1.00      1.00      1.00         7\n",
      "          74       1.00      1.00      1.00         6\n",
      "          75       1.00      1.00      1.00         6\n",
      "          76       1.00      1.00      1.00         6\n",
      "          77       1.00      1.00      1.00         6\n",
      "          78       1.00      1.00      1.00         6\n",
      "          79       1.00      1.00      1.00         6\n",
      "          80       1.00      1.00      1.00         6\n",
      "          81       0.00      0.00      0.00         7\n",
      "          82       0.00      0.00      0.00         7\n",
      "          83       1.00      1.00      1.00         6\n",
      "          84       0.00      0.00      0.00         7\n",
      "          85       1.00      1.00      1.00         6\n",
      "          86       1.00      1.00      1.00         6\n",
      "          87       1.00      1.00      1.00         6\n",
      "          88       1.00      1.00      1.00         6\n",
      "          89       1.00      1.00      1.00         6\n",
      "          90       1.00      1.00      1.00         6\n",
      "          91       1.00      1.00      1.00         6\n",
      "          92       0.00      0.00      0.00         7\n",
      "          93       0.00      0.00      0.00         7\n",
      "          94       0.00      0.00      0.00         7\n",
      "          95       0.46      1.00      0.63         6\n",
      "          96       1.00      1.00      1.00         6\n",
      "          97       0.00      0.00      0.00         7\n",
      "          98       1.00      1.00      1.00         6\n",
      "          99       1.00      1.00      1.00         6\n",
      "         100       1.00      1.00      1.00         6\n",
      "         101       1.00      1.00      1.00         6\n",
      "         102       0.46      1.00      0.63         6\n",
      "         103       1.00      1.00      1.00         6\n",
      "         104       0.00      0.00      0.00         7\n",
      "         105       1.00      1.00      1.00         6\n",
      "         106       0.46      1.00      0.63         6\n",
      "         107       0.00      0.00      0.00         7\n",
      "         108       0.00      0.00      0.00         7\n",
      "         109       0.46      1.00      0.63         6\n",
      "         110       0.46      1.00      0.63         6\n",
      "         111       0.00      0.00      0.00         7\n",
      "         112       0.00      0.00      0.00         7\n",
      "         113       1.00      1.00      1.00         6\n",
      "         114       1.00      1.00      1.00         6\n",
      "         115       1.00      1.00      1.00         6\n",
      "         116       1.00      1.00      1.00         6\n",
      "         117       1.00      1.00      1.00         6\n",
      "         118       0.46      1.00      0.63         6\n",
      "         119       1.00      1.00      1.00         6\n",
      "         120       1.00      1.00      1.00         6\n",
      "         121       1.00      1.00      1.00         7\n",
      "         122       1.00      1.00      1.00         6\n",
      "         123       1.00      1.00      1.00         6\n",
      "         124       1.00      1.00      1.00         6\n",
      "         125       1.00      1.00      1.00         6\n",
      "         126       0.00      0.00      0.00         7\n",
      "         127       1.00      1.00      1.00         6\n",
      "         128       1.00      1.00      1.00         6\n",
      "         129       1.00      1.00      1.00         6\n",
      "         130       1.00      1.00      1.00         6\n",
      "         131       1.00      1.00      1.00         6\n",
      "         132       1.00      1.00      1.00         6\n",
      "         133       0.46      1.00      0.63         6\n",
      "         134       0.00      0.00      0.00         7\n",
      "         135       1.00      1.00      1.00         7\n",
      "         136       0.00      0.00      0.00         7\n",
      "         137       0.46      1.00      0.63         6\n",
      "         138       1.00      1.00      1.00         6\n",
      "         139       1.00      1.00      1.00         7\n",
      "         140       1.00      1.00      1.00         6\n",
      "         141       0.46      1.00      0.63         6\n",
      "         142       1.00      1.00      1.00         6\n",
      "         143       0.46      1.00      0.63         6\n",
      "         144       0.46      1.00      0.63         6\n",
      "         145       1.00      1.00      1.00         6\n",
      "         146       1.00      1.00      1.00         6\n",
      "         147       1.00      1.00      1.00         6\n",
      "         148       1.00      1.00      1.00         6\n",
      "         149       1.00      1.00      1.00         6\n",
      "         150       0.30      1.00      0.46         6\n",
      "         151       0.46      1.00      0.63         6\n",
      "         152       0.30      1.00      0.46         6\n",
      "         153       0.00      0.00      0.00         7\n",
      "         154       1.00      1.00      1.00         6\n",
      "         155       0.00      0.00      0.00         7\n",
      "         156       1.00      1.00      1.00         6\n",
      "         157       1.00      1.00      1.00         6\n",
      "         158       1.00      1.00      1.00         6\n",
      "         159       1.00      1.00      1.00         6\n",
      "         160       0.00      0.00      0.00         7\n",
      "         161       1.00      1.00      1.00         6\n",
      "         162       1.00      1.00      1.00         6\n",
      "         163       1.00      1.00      1.00         6\n",
      "         164       1.00      1.00      1.00         6\n",
      "         165       0.46      1.00      0.63         6\n",
      "         166       1.00      1.00      1.00         6\n",
      "         167       0.46      1.00      0.63         6\n",
      "         168       0.00      0.00      0.00         7\n",
      "         169       0.30      1.00      0.46         6\n",
      "         170       0.46      1.00      0.63         6\n",
      "         171       0.00      0.00      0.00         7\n",
      "         172       1.00      1.00      1.00         6\n",
      "         173       1.00      1.00      1.00         6\n",
      "         174       1.00      1.00      1.00         6\n",
      "         175       0.00      0.00      0.00         7\n",
      "         176       0.46      1.00      0.63         6\n",
      "         177       1.00      1.00      1.00         6\n",
      "         178       0.30      1.00      0.46         6\n",
      "         179       1.00      1.00      1.00         6\n",
      "         180       1.00      1.00      1.00         6\n",
      "         181       0.46      1.00      0.63         6\n",
      "         182       0.46      1.00      0.63         6\n",
      "         183       1.00      1.00      1.00         6\n",
      "         184       1.00      1.00      1.00         6\n",
      "         185       1.00      1.00      1.00         6\n",
      "         186       0.00      0.00      0.00         7\n",
      "         187       0.00      0.00      0.00         7\n",
      "         188       1.00      1.00      1.00         6\n",
      "         189       0.00      0.00      0.00         7\n",
      "         190       0.46      1.00      0.63         6\n",
      "         191       1.00      1.00      1.00         6\n",
      "         192       0.30      1.00      0.46         6\n",
      "         193       0.46      1.00      0.63         6\n",
      "         194       0.46      1.00      0.63         6\n",
      "         195       1.00      1.00      1.00         6\n",
      "         196       1.00      1.00      1.00         6\n",
      "         197       0.46      1.00      0.63         6\n",
      "         198       0.46      1.00      0.63         6\n",
      "         199       0.00      0.00      0.00         7\n",
      "         200       0.00      0.00      0.00         7\n",
      "         201       0.46      1.00      0.63         6\n",
      "         202       0.46      1.00      0.63         6\n",
      "         203       1.00      1.00      1.00         6\n",
      "         204       1.00      1.00      1.00         6\n",
      "         205       1.00      1.00      1.00         7\n",
      "         206       1.00      1.00      1.00         6\n",
      "         207       0.00      0.00      0.00         7\n",
      "         208       1.00      1.00      1.00         6\n",
      "         209       1.00      1.00      1.00         6\n",
      "         210       1.00      1.00      1.00         6\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       1.00      1.00      1.00         6\n",
      "         213       0.30      1.00      0.46         6\n",
      "         214       0.00      0.00      0.00         7\n",
      "         215       0.46      1.00      0.63         6\n",
      "         216       1.00      1.00      1.00         6\n",
      "         217       0.00      0.00      0.00         7\n",
      "         218       1.00      1.00      1.00         6\n",
      "         219       0.46      1.00      0.63         6\n",
      "         220       1.00      1.00      1.00         6\n",
      "         221       0.00      0.00      0.00         7\n",
      "         222       0.46      1.00      0.63         6\n",
      "         223       1.00      1.00      1.00         6\n",
      "         224       0.46      1.00      0.63         6\n",
      "         225       1.00      1.00      1.00         6\n",
      "         226       1.00      1.00      1.00         6\n",
      "         227       1.00      1.00      1.00         6\n",
      "         228       0.00      0.00      0.00         7\n",
      "         229       1.00      1.00      1.00         6\n",
      "         230       1.00      1.00      1.00         6\n",
      "         231       1.00      1.00      1.00         6\n",
      "         232       1.00      1.00      1.00         6\n",
      "         233       1.00      1.00      1.00         6\n",
      "         234       1.00      1.00      1.00         6\n",
      "         235       0.00      0.00      0.00         7\n",
      "         236       1.00      1.00      1.00         6\n",
      "         237       0.00      0.00      0.00         7\n",
      "         238       0.00      0.00      0.00         7\n",
      "         239       1.00      1.00      1.00         6\n",
      "         240       0.30      1.00      0.46         6\n",
      "         241       0.00      0.00      0.00         7\n",
      "         242       0.00      0.00      0.00         7\n",
      "         243       0.00      0.00      0.00         7\n",
      "         244       1.00      1.00      1.00         6\n",
      "         245       1.00      1.00      1.00         6\n",
      "         246       0.46      1.00      0.63         6\n",
      "         247       1.00      1.00      1.00         6\n",
      "         248       1.00      1.00      1.00         6\n",
      "         249       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.76      1563\n",
      "   macro avg       0.69      0.79      0.72      1563\n",
      "weighted avg       0.66      0.76      0.69      1563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# These features show higher precision scores - but only one dataset is being used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 4: New \"y\" Data, and Features\n",
    "## Comparing Comparing Pollutant (Nitrogen Dioxide and Sulfur Dioxide) Levels to Household Income"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_name',\n",
       " 'year',\n",
       " 'Population',\n",
       " 'HHI',\n",
       " 'PovertyRate',\n",
       " 'state_id',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees',\n",
       " 'Days_with_AQI',\n",
       " 'Year',\n",
       " 'Good_Days',\n",
       " 'Moderate_Days',\n",
       " 'Unhealthy_Days',\n",
       " 'Very_Unhealthy_Days',\n",
       " 'Hazardous_Days',\n",
       " 'Days_CO',\n",
       " 'Days_NO2',\n",
       " 'Days_Ozone',\n",
       " 'Days_SO2',\n",
       " 'Days_PM2_5',\n",
       " 'Days_PM10']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names \n",
    "\n",
    "list(data_all.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['Days_NO2', 'Days_SO2']]\n",
    "y_data = data_all[['HHI']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days_NO2</th>\n",
       "      <th>Days_SO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1911</th>\n",
       "      <td>6.15</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4865</th>\n",
       "      <td>3.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3938</th>\n",
       "      <td>7.69</td>\n",
       "      <td>4.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5324</th>\n",
       "      <td>4.41</td>\n",
       "      <td>1.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4759</th>\n",
       "      <td>20.67</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Days_NO2  Days_SO2\n",
       "1911      6.15      0.85\n",
       "4865      3.67      0.00\n",
       "3938      7.69      4.41\n",
       "5324      4.41      1.49\n",
       "4759     20.67      0.00"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 61   0 124 ... 196  14 205]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.07808832942180499\n",
      "Testing Data Score: 0.044145873320537425\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         6\n",
      "           1       0.00      0.00      0.00         7\n",
      "           2       0.00      0.00      0.00         6\n",
      "           3       0.00      0.00      0.00         6\n",
      "           4       0.09      0.67      0.16         6\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.00      0.00      0.00         6\n",
      "           7       0.00      0.00      0.00         6\n",
      "           8       0.00      0.00      0.00         7\n",
      "           9       0.00      0.00      0.00         6\n",
      "          10       0.00      0.00      0.00         6\n",
      "          11       0.07      0.50      0.12         6\n",
      "          12       0.00      0.00      0.00         6\n",
      "          13       0.00      0.00      0.00         7\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       0.09      0.33      0.14         6\n",
      "          16       0.00      0.00      0.00         6\n",
      "          17       0.00      0.00      0.00         7\n",
      "          18       0.11      0.17      0.13         6\n",
      "          19       0.03      0.17      0.05         6\n",
      "          20       0.00      0.00      0.00         7\n",
      "          21       0.00      0.00      0.00         7\n",
      "          22       0.00      0.00      0.00         6\n",
      "          23       0.00      0.00      0.00         6\n",
      "          24       0.00      0.00      0.00         6\n",
      "          25       0.00      0.00      0.00         6\n",
      "          26       0.00      0.00      0.00         6\n",
      "          27       0.09      0.17      0.12         6\n",
      "          28       0.00      0.00      0.00         6\n",
      "          29       0.00      0.00      0.00         6\n",
      "          30       0.00      0.00      0.00         6\n",
      "          31       0.00      0.00      0.00         6\n",
      "          32       0.00      0.00      0.00         6\n",
      "          33       0.00      0.00      0.00         6\n",
      "          34       0.00      0.00      0.00         6\n",
      "          35       0.00      0.00      0.00         6\n",
      "          36       0.00      0.00      0.00         6\n",
      "          37       0.00      0.00      0.00         7\n",
      "          38       0.00      0.00      0.00         6\n",
      "          39       0.00      0.00      0.00         6\n",
      "          40       0.00      0.00      0.00         6\n",
      "          41       0.00      0.00      0.00         6\n",
      "          42       0.00      0.00      0.00         6\n",
      "          43       0.00      0.00      0.00         6\n",
      "          44       0.00      0.00      0.00         6\n",
      "          45       0.00      0.00      0.00         6\n",
      "          46       0.04      0.17      0.07         6\n",
      "          47       0.00      0.00      0.00         6\n",
      "          48       0.00      0.00      0.00         7\n",
      "          49       0.00      0.00      0.00         6\n",
      "          50       0.00      0.00      0.00         7\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       0.00      0.00      0.00         7\n",
      "          53       0.00      0.00      0.00         6\n",
      "          54       0.00      0.00      0.00         7\n",
      "          55       0.06      0.17      0.09         6\n",
      "          56       0.10      0.50      0.17         6\n",
      "          57       0.00      0.00      0.00         7\n",
      "          58       0.00      0.00      0.00         7\n",
      "          59       0.00      0.00      0.00         7\n",
      "          60       0.00      0.00      0.00         6\n",
      "          61       0.00      0.00      0.00         6\n",
      "          62       0.05      0.17      0.08         6\n",
      "          63       0.00      0.00      0.00         7\n",
      "          64       0.00      0.00      0.00         6\n",
      "          65       0.00      0.00      0.00         6\n",
      "          66       0.00      0.00      0.00         6\n",
      "          67       0.08      0.33      0.13         6\n",
      "          68       0.00      0.00      0.00         6\n",
      "          69       0.00      0.00      0.00         6\n",
      "          70       0.00      0.00      0.00         6\n",
      "          71       0.00      0.00      0.00         7\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       0.00      0.00      0.00         6\n",
      "          74       0.00      0.00      0.00         7\n",
      "          75       0.00      0.00      0.00         6\n",
      "          76       0.00      0.00      0.00         6\n",
      "          77       0.00      0.00      0.00         6\n",
      "          78       0.00      0.00      0.00         6\n",
      "          79       0.00      0.00      0.00         6\n",
      "          80       0.10      0.33      0.15         6\n",
      "          81       0.00      0.00      0.00         6\n",
      "          82       0.07      0.17      0.10         6\n",
      "          83       0.00      0.00      0.00         6\n",
      "          84       0.00      0.00      0.00         6\n",
      "          85       0.00      0.00      0.00         6\n",
      "          86       0.00      0.00      0.00         6\n",
      "          87       0.00      0.00      0.00         7\n",
      "          88       0.00      0.00      0.00         7\n",
      "          89       0.00      0.00      0.00         7\n",
      "          90       0.00      0.00      0.00         6\n",
      "          91       0.00      0.00      0.00         6\n",
      "          92       0.00      0.00      0.00         7\n",
      "          93       0.00      0.00      0.00         6\n",
      "          94       0.00      0.00      0.00         6\n",
      "          95       0.00      0.00      0.00         6\n",
      "          96       0.00      0.00      0.00         6\n",
      "          97       0.00      0.00      0.00         6\n",
      "          98       0.00      0.00      0.00         6\n",
      "          99       0.00      0.00      0.00         7\n",
      "         100       0.00      0.00      0.00         6\n",
      "         101       0.09      0.17      0.12         6\n",
      "         102       0.00      0.00      0.00         7\n",
      "         103       0.00      0.00      0.00         7\n",
      "         104       0.03      0.17      0.05         6\n",
      "         105       0.00      0.00      0.00         6\n",
      "         106       0.00      0.00      0.00         7\n",
      "         107       0.00      0.00      0.00         7\n",
      "         108       0.00      0.00      0.00         6\n",
      "         109       0.22      0.33      0.27         6\n",
      "         110       0.10      0.33      0.15         6\n",
      "         111       0.00      0.00      0.00         6\n",
      "         112       0.00      0.00      0.00         6\n",
      "         113       0.00      0.00      0.00         6\n",
      "         114       0.00      0.00      0.00         6\n",
      "         115       0.00      0.00      0.00         6\n",
      "         116       0.00      0.00      0.00         7\n",
      "         117       0.00      0.00      0.00         6\n",
      "         118       0.00      0.00      0.00         6\n",
      "         119       0.07      0.33      0.12         6\n",
      "         120       0.00      0.00      0.00         6\n",
      "         121       0.00      0.00      0.00         7\n",
      "         122       0.00      0.00      0.00         6\n",
      "         123       0.00      0.00      0.00         6\n",
      "         124       0.00      0.00      0.00         6\n",
      "         125       0.00      0.00      0.00         6\n",
      "         126       0.00      0.00      0.00         6\n",
      "         127       0.16      0.50      0.24         6\n",
      "         128       0.00      0.00      0.00         6\n",
      "         129       0.00      0.00      0.00         7\n",
      "         130       0.00      0.00      0.00         7\n",
      "         131       0.00      0.00      0.00         7\n",
      "         132       0.02      0.69      0.05        13\n",
      "         133       0.00      0.00      0.00         6\n",
      "         134       0.04      0.33      0.08         6\n",
      "         135       0.00      0.00      0.00         7\n",
      "         136       0.00      0.00      0.00         6\n",
      "         137       0.00      0.00      0.00         6\n",
      "         138       0.00      0.00      0.00         6\n",
      "         139       0.17      0.17      0.17         6\n",
      "         140       0.00      0.00      0.00         6\n",
      "         141       0.00      0.00      0.00         6\n",
      "         142       0.00      0.00      0.00         6\n",
      "         143       0.02      0.17      0.04         6\n",
      "         144       0.00      0.00      0.00         6\n",
      "         145       0.00      0.00      0.00         6\n",
      "         146       0.00      0.00      0.00         6\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.00      0.00      0.00         6\n",
      "         149       0.00      0.00      0.00         6\n",
      "         150       0.00      0.00      0.00         7\n",
      "         151       0.00      0.00      0.00         6\n",
      "         152       0.00      0.00      0.00         7\n",
      "         153       0.03      0.17      0.05         6\n",
      "         154       0.00      0.00      0.00         6\n",
      "         155       0.00      0.00      0.00         6\n",
      "         156       0.00      0.00      0.00         6\n",
      "         157       0.00      0.00      0.00         6\n",
      "         158       0.00      0.00      0.00         7\n",
      "         159       0.00      0.00      0.00         6\n",
      "         160       0.00      0.00      0.00         6\n",
      "         161       0.00      0.00      0.00         7\n",
      "         162       0.00      0.00      0.00         6\n",
      "         163       0.00      0.00      0.00         6\n",
      "         164       0.00      0.00      0.00         6\n",
      "         165       0.00      0.00      0.00         6\n",
      "         166       0.00      0.00      0.00         6\n",
      "         167       0.00      0.00      0.00         7\n",
      "         168       0.00      0.00      0.00         6\n",
      "         169       0.10      0.33      0.15         6\n",
      "         170       0.00      0.00      0.00         7\n",
      "         171       0.00      0.00      0.00         6\n",
      "         172       0.00      0.00      0.00         6\n",
      "         173       0.00      0.00      0.00         6\n",
      "         174       0.00      0.00      0.00         6\n",
      "         175       0.00      0.00      0.00         7\n",
      "         176       0.08      0.33      0.13         6\n",
      "         177       0.10      0.67      0.17         6\n",
      "         178       0.02      0.17      0.03         6\n",
      "         179       0.00      0.00      0.00         6\n",
      "         180       0.00      0.00      0.00         7\n",
      "         181       0.00      0.00      0.00         6\n",
      "         182       0.00      0.00      0.00         6\n",
      "         183       0.00      0.00      0.00         6\n",
      "         184       0.00      0.00      0.00         6\n",
      "         185       0.00      0.00      0.00         6\n",
      "         186       0.00      0.00      0.00         6\n",
      "         187       0.09      0.33      0.14         6\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       0.00      0.00      0.00         7\n",
      "         190       0.00      0.00      0.00         7\n",
      "         191       0.00      0.00      0.00         6\n",
      "         192       0.00      0.00      0.00         7\n",
      "         193       0.00      0.00      0.00         6\n",
      "         194       0.00      0.00      0.00         6\n",
      "         195       0.00      0.00      0.00         6\n",
      "         196       0.00      0.00      0.00         6\n",
      "         197       0.00      0.00      0.00         6\n",
      "         198       0.00      0.00      0.00         6\n",
      "         199       0.13      0.50      0.21         6\n",
      "         200       0.00      0.00      0.00         6\n",
      "         201       0.00      0.00      0.00         6\n",
      "         202       0.00      0.00      0.00         6\n",
      "         203       0.00      0.00      0.00         7\n",
      "         204       0.00      0.00      0.00         7\n",
      "         205       0.04      0.17      0.06         6\n",
      "         206       0.00      0.00      0.00         7\n",
      "         207       0.00      0.00      0.00         7\n",
      "         208       0.00      0.00      0.00         7\n",
      "         209       0.06      0.33      0.10         6\n",
      "         210       0.00      0.00      0.00         6\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.00      0.00      0.00         6\n",
      "         213       0.00      0.00      0.00         6\n",
      "         214       0.00      0.00      0.00         7\n",
      "         215       0.00      0.00      0.00         7\n",
      "         216       0.25      0.17      0.20         6\n",
      "         217       0.00      0.00      0.00         6\n",
      "         218       0.00      0.00      0.00         6\n",
      "         219       0.00      0.00      0.00         7\n",
      "         220       0.00      0.00      0.00         7\n",
      "         221       0.00      0.00      0.00         6\n",
      "         222       0.09      0.17      0.12         6\n",
      "         223       0.11      0.33      0.16         6\n",
      "         224       0.00      0.00      0.00         6\n",
      "         225       0.00      0.00      0.00         6\n",
      "         226       0.00      0.00      0.00         6\n",
      "         227       0.00      0.00      0.00         6\n",
      "         228       0.00      0.00      0.00         6\n",
      "         229       0.00      0.00      0.00         7\n",
      "         230       0.00      0.00      0.00         6\n",
      "         231       0.00      0.00      0.00         6\n",
      "         232       0.00      0.00      0.00         6\n",
      "         233       0.00      0.00      0.00         6\n",
      "         234       0.00      0.00      0.00         7\n",
      "         235       0.00      0.00      0.00         7\n",
      "         236       0.00      0.00      0.00         6\n",
      "         237       0.00      0.00      0.00         6\n",
      "         238       0.00      0.00      0.00         6\n",
      "         239       0.00      0.00      0.00         6\n",
      "         240       0.00      0.00      0.00         6\n",
      "         241       0.00      0.00      0.00         7\n",
      "         242       0.00      0.00      0.00         6\n",
      "         243       0.00      0.00      0.00         6\n",
      "         244       0.00      0.00      0.00         6\n",
      "         245       0.00      0.00      0.00         7\n",
      "         246       0.00      0.00      0.00         6\n",
      "         247       0.00      0.00      0.00         6\n",
      "         248       0.00      0.00      0.00         7\n",
      "\n",
      "    accuracy                           0.04      1563\n",
      "   macro avg       0.01      0.04      0.02      1563\n",
      "weighted avg       0.01      0.04      0.02      1563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"HHI\"]\n",
    "target_names = data_all[\"HHI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"HHI\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.21514609791537756, 'PovertyRate'),\n",
       " (0.21182204465079735, 'Population'),\n",
       " (0.18226480023497468, 'year'),\n",
       " (0.034584750102425156, 'state_id'),\n",
       " (0.02731308046178275, 'average_diabetic_enrollees_eye_exam'),\n",
       " (0.027189425752773215, 'beneficiaries_part_b'),\n",
       " (0.024024610701387776, 'diabetic_enrollees_age_65_to_75'),\n",
       " (0.022133094722691732, 'average_female_age_67_to_69_mammogram'),\n",
       " (0.021376244767316713, 'one_ambulatory_visit'),\n",
       " (0.020774497939538214, 'Days_PM10'),\n",
       " (0.02047446046868115, 'Days_PM2_5'),\n",
       " (0.020269590098765042, 'average_female_enrollees_age_67_to_69'),\n",
       " (0.01806070209330679, 'Days_Ozone'),\n",
       " (0.01763556063220183, 'average_diabetic_enrollees_hemoglobin_a1c_test'),\n",
       " (0.0175765300808366, 'average_diabetic_enrollees_blood_lipids_test'),\n",
       " (0.017526033625124855, 'Days_SO2'),\n",
       " (0.01592691733149219, 'Days_NO2'),\n",
       " (0.015859885205891447, 'Days_with_AQI'),\n",
       " (0.015668691292024133, 'beneficiaries_part_a_eligible'),\n",
       " (0.009632301117140304, 'Good_Days'),\n",
       " (0.009614445722850142, 'Moderate_Days'),\n",
       " (0.007937283173520755,\n",
       "  'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees'),\n",
       " (0.00761195109743642, 'leg_amputations_per_1000_enrollees'),\n",
       " (0.005727533106069805, 'Hazardous_Days'),\n",
       " (0.005589184297262355, 'Unhealthy_Days'),\n",
       " (0.003569446027510448, 'Year'),\n",
       " (0.0031657009071244984, 'Days_CO'),\n",
       " (0.0015251364736960532, 'Very_Unhealthy_Days')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "# shows the features most likely to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 5: New Features\n",
    "## Comparing Income and Part B Beneficiaries to Poverty Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['beneficiaries_part_b', 'HHI']]\n",
    "y_data = data_all[['PovertyRate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "      <th>HHI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>123966.0</td>\n",
       "      <td>46230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>534414.0</td>\n",
       "      <td>44587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>497193.0</td>\n",
       "      <td>44623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>577944.0</td>\n",
       "      <td>48173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>1837381.0</td>\n",
       "      <td>47212</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      beneficiaries_part_b    HHI\n",
       "3186              123966.0  46230\n",
       "4890              534414.0  44587\n",
       "4904              497193.0  44623\n",
       "3124              577944.0  48173\n",
       "1084             1837381.0  47212"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 83  22 146 ... 219  36 228]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.6799658630253894\n",
      "Testing Data Score: 0.6257197696737045\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.30      1.00      0.46         6\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       0.46      1.00      0.63         6\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       1.00      1.00      1.00         6\n",
      "           9       1.00      1.00      1.00         6\n",
      "          10       1.00      1.00      1.00         6\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.46      1.00      0.63         6\n",
      "          13       1.00      1.00      1.00         6\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       1.00      1.00      1.00         6\n",
      "          16       0.46      1.00      0.63         6\n",
      "          17       1.00      1.00      1.00         6\n",
      "          18       0.00      0.00      0.00         7\n",
      "          19       1.00      1.00      1.00         6\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       0.00      0.00      0.00         7\n",
      "          22       0.46      1.00      0.63         6\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.46      1.00      0.63         6\n",
      "          25       0.57      0.67      0.62         6\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       0.22      1.00      0.36         6\n",
      "          28       0.25      0.17      0.20         6\n",
      "          29       0.38      0.50      0.43         6\n",
      "          30       0.00      0.00      0.00         7\n",
      "          31       0.46      1.00      0.63         6\n",
      "          32       0.60      0.50      0.55         6\n",
      "          33       1.00      1.00      1.00         6\n",
      "          34       1.00      1.00      1.00         6\n",
      "          35       0.00      0.00      0.00         7\n",
      "          36       0.00      0.00      0.00         7\n",
      "          37       1.00      1.00      1.00         6\n",
      "          38       1.00      1.00      1.00         6\n",
      "          39       0.00      0.00      0.00         7\n",
      "          40       0.46      1.00      0.63         6\n",
      "          41       1.00      1.00      1.00         6\n",
      "          42       0.00      0.00      0.00         7\n",
      "          43       0.00      0.00      0.00         7\n",
      "          44       0.46      1.00      0.63         6\n",
      "          45       1.00      1.00      1.00         6\n",
      "          46       1.00      1.00      1.00         6\n",
      "          47       0.33      0.33      0.33         6\n",
      "          48       1.00      1.00      1.00         6\n",
      "          49       0.33      0.33      0.33         6\n",
      "          50       1.00      1.00      1.00         6\n",
      "          51       1.00      1.00      1.00         6\n",
      "          52       0.67      1.00      0.80         6\n",
      "          53       0.46      1.00      0.63         6\n",
      "          54       1.00      1.00      1.00         6\n",
      "          55       1.00      1.00      1.00         6\n",
      "          56       1.00      1.00      1.00         6\n",
      "          57       1.00      1.00      1.00         6\n",
      "          58       0.46      1.00      0.63         6\n",
      "          59       0.00      0.00      0.00         7\n",
      "          60       0.43      1.00      0.60         6\n",
      "          61       1.00      1.00      1.00         6\n",
      "          62       1.00      1.00      1.00         6\n",
      "          63       1.00      1.00      1.00         6\n",
      "          64       1.00      1.00      1.00         6\n",
      "          65       1.00      1.00      1.00         6\n",
      "          66       0.46      1.00      0.63         6\n",
      "          67       0.46      1.00      0.63         6\n",
      "          68       1.00      1.00      1.00         6\n",
      "          69       0.46      1.00      0.63         6\n",
      "          70       0.00      0.00      0.00         7\n",
      "          71       1.00      1.00      1.00         6\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       1.00      1.00      1.00         6\n",
      "          74       0.00      0.00      0.00         7\n",
      "          75       1.00      1.00      1.00         6\n",
      "          76       0.00      0.00      0.00         7\n",
      "          77       1.00      1.00      1.00         6\n",
      "          78       1.00      1.00      1.00         6\n",
      "          79       0.00      0.00      0.00         7\n",
      "          80       0.00      0.00      0.00         7\n",
      "          81       0.00      0.00      0.00         7\n",
      "          82       0.43      1.00      0.60         6\n",
      "          83       1.00      1.00      1.00         6\n",
      "          84       0.46      1.00      0.63         6\n",
      "          85       0.00      0.00      0.00         7\n",
      "          86       1.00      1.00      1.00         6\n",
      "          87       1.00      1.00      1.00         6\n",
      "          88       1.00      1.00      1.00         6\n",
      "          89       1.00      1.00      1.00         6\n",
      "          90       1.00      1.00      1.00         6\n",
      "          91       1.00      1.00      1.00         6\n",
      "          92       0.25      0.33      0.29         6\n",
      "          93       0.00      0.00      0.00         7\n",
      "          94       0.00      0.00      0.00         7\n",
      "          95       1.00      1.00      1.00         6\n",
      "          96       0.00      0.00      0.00         7\n",
      "          97       0.40      1.00      0.57         6\n",
      "          98       0.31      0.67      0.42         6\n",
      "          99       1.00      1.00      1.00         6\n",
      "         100       0.46      1.00      0.63         6\n",
      "         101       0.60      1.00      0.75         6\n",
      "         102       0.30      1.00      0.46         6\n",
      "         103       0.60      1.00      0.75         6\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       0.32      1.00      0.48         6\n",
      "         106       1.00      1.00      1.00         6\n",
      "         107       0.14      0.33      0.20         6\n",
      "         108       1.00      1.00      1.00         6\n",
      "         109       0.00      0.00      0.00         7\n",
      "         110       0.00      0.00      0.00         7\n",
      "         111       0.00      0.00      0.00         7\n",
      "         112       1.00      1.00      1.00         6\n",
      "         113       0.27      0.50      0.35         6\n",
      "         114       0.00      0.00      0.00         7\n",
      "         115       1.00      1.00      1.00         6\n",
      "         116       1.00      1.00      1.00         6\n",
      "         117       1.00      1.00      1.00         6\n",
      "         118       0.46      1.00      0.63         6\n",
      "         119       1.00      1.00      1.00         6\n",
      "         120       1.00      1.00      1.00         6\n",
      "         121       0.00      0.00      0.00         7\n",
      "         122       1.00      1.00      1.00         6\n",
      "         123       0.17      0.33      0.22         6\n",
      "         124       0.00      0.00      0.00         7\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       1.00      1.00      1.00         6\n",
      "         127       1.00      1.00      1.00         6\n",
      "         128       0.00      0.00      0.00         7\n",
      "         129       0.00      0.00      0.00         7\n",
      "         130       0.00      0.00      0.00         6\n",
      "         131       0.75      1.00      0.86         6\n",
      "         132       1.00      1.00      1.00         6\n",
      "         133       0.43      0.50      0.46         6\n",
      "         134       1.00      1.00      1.00         6\n",
      "         135       1.00      1.00      1.00         6\n",
      "         136       1.00      1.00      1.00         6\n",
      "         137       1.00      1.00      1.00         6\n",
      "         138       0.00      0.00      0.00         7\n",
      "         139       0.46      1.00      0.63         6\n",
      "         140       1.00      1.00      1.00         6\n",
      "         141       1.00      0.83      0.91         6\n",
      "         142       1.00      1.00      1.00         6\n",
      "         143       0.00      0.00      0.00         7\n",
      "         144       1.00      1.00      1.00         6\n",
      "         145       1.00      1.00      1.00         6\n",
      "         146       0.46      1.00      0.63         6\n",
      "         147       0.45      0.83      0.59         6\n",
      "         148       0.67      0.67      0.67         6\n",
      "         149       0.00      0.00      0.00         6\n",
      "         150       0.30      1.00      0.46         6\n",
      "         151       0.00      0.00      0.00         7\n",
      "         152       0.00      0.00      0.00         7\n",
      "         153       0.00      0.00      0.00         7\n",
      "         154       1.00      1.00      1.00         6\n",
      "         155       0.75      1.00      0.86         6\n",
      "         156       0.00      0.00      0.00         7\n",
      "         157       0.46      1.00      0.63         6\n",
      "         158       1.00      1.00      1.00         6\n",
      "         159       0.46      1.00      0.63         6\n",
      "         160       0.27      0.50      0.35         6\n",
      "         161       1.00      1.00      1.00         6\n",
      "         162       0.23      0.50      0.32         6\n",
      "         163       1.00      1.00      1.00         6\n",
      "         164       0.86      1.00      0.92         6\n",
      "         165       0.44      0.67      0.53         6\n",
      "         166       0.60      1.00      0.75         6\n",
      "         167       1.00      0.33      0.50         6\n",
      "         168       0.33      0.67      0.44         6\n",
      "         169       1.00      0.83      0.91         6\n",
      "         170       1.00      1.00      1.00         6\n",
      "         171       0.00      0.00      0.00         7\n",
      "         172       1.00      0.33      0.50         6\n",
      "         173       0.00      0.00      0.00         7\n",
      "         174       1.00      1.00      1.00         6\n",
      "         175       1.00      0.67      0.80         6\n",
      "         176       0.16      0.50      0.24         6\n",
      "         177       1.00      1.00      1.00         6\n",
      "         178       1.00      0.67      0.80         6\n",
      "         179       0.00      0.00      0.00         7\n",
      "         180       1.00      1.00      1.00         6\n",
      "         181       0.62      0.83      0.71         6\n",
      "         182       0.00      0.00      0.00         7\n",
      "         183       1.00      1.00      1.00         6\n",
      "         184       0.46      1.00      0.63         6\n",
      "         185       1.00      1.00      1.00         6\n",
      "         186       0.29      0.33      0.31         6\n",
      "         187       0.00      0.00      0.00         6\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       0.00      0.00      0.00         6\n",
      "         190       0.45      0.83      0.59         6\n",
      "         191       0.00      0.00      0.00         7\n",
      "         192       0.43      0.50      0.46         6\n",
      "         193       0.46      1.00      0.63         6\n",
      "         194       1.00      1.00      1.00         6\n",
      "         195       0.40      0.67      0.50         6\n",
      "         196       0.00      0.00      0.00         7\n",
      "         197       0.23      0.50      0.32         6\n",
      "         198       1.00      1.00      1.00         6\n",
      "         199       0.18      0.33      0.24         6\n",
      "         200       0.00      0.00      0.00         6\n",
      "         201       0.00      0.00      0.00         7\n",
      "         202       0.42      0.83      0.56         6\n",
      "         203       1.00      1.00      1.00         6\n",
      "         204       0.67      1.00      0.80         6\n",
      "         205       0.35      1.00      0.52         6\n",
      "         206       0.50      0.50      0.50         6\n",
      "         207       1.00      1.00      1.00         6\n",
      "         208       0.46      1.00      0.63         6\n",
      "         209       0.00      0.00      0.00         7\n",
      "         210       0.00      0.00      0.00         7\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.50      0.33      0.40         6\n",
      "         213       0.00      0.00      0.00         7\n",
      "         214       0.46      1.00      0.63         6\n",
      "         215       0.46      1.00      0.63         6\n",
      "         216       0.67      0.67      0.67         6\n",
      "         217       0.46      1.00      0.63         6\n",
      "         218       0.45      0.83      0.59         6\n",
      "         219       0.40      0.33      0.36         6\n",
      "         220       0.50      0.67      0.57         6\n",
      "         221       1.00      1.00      1.00         6\n",
      "         222       0.86      1.00      0.92         6\n",
      "         223       0.00      0.00      0.00         6\n",
      "         224       0.00      0.00      0.00         7\n",
      "         225       0.00      0.00      0.00         7\n",
      "         226       0.00      0.00      0.00         7\n",
      "         227       0.67      0.67      0.67         6\n",
      "         228       0.46      1.00      0.63         6\n",
      "         229       0.00      0.00      0.00         7\n",
      "         230       0.00      0.00      0.00         7\n",
      "         231       0.30      1.00      0.46         6\n",
      "         232       0.00      0.00      0.00         7\n",
      "         233       0.46      1.00      0.63         6\n",
      "         234       0.46      1.00      0.63         6\n",
      "         235       1.00      1.00      1.00         6\n",
      "         236       0.00      0.00      0.00         7\n",
      "         237       0.00      0.00      0.00         7\n",
      "         238       0.46      1.00      0.63         6\n",
      "         239       1.00      1.00      1.00         6\n",
      "         240       0.50      1.00      0.67         6\n",
      "         241       1.00      1.00      1.00         6\n",
      "         242       0.00      0.00      0.00         7\n",
      "         243       0.00      0.00      0.00         7\n",
      "         244       0.43      1.00      0.60         6\n",
      "         245       1.00      1.00      1.00         6\n",
      "         246       1.00      1.00      1.00         6\n",
      "         247       1.00      1.00      1.00         6\n",
      "         248       1.00      1.00      1.00         6\n",
      "         249       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.63      1563\n",
      "   macro avg       0.54      0.65      0.57      1563\n",
      "weighted avg       0.51      0.63      0.55      1563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"PovertyRate\"]\n",
    "target_names = data_all[\"PovertyRate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"PovertyRate\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = tree.DecisionTreeClassifier()\n",
    "# clf = clf.fit(X_train, y_train)\n",
    "# clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# rf = RandomForestClassifier(n_estimators=200)\n",
    "# rf = rf.fit(X_train, y_train)\n",
    "# rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "# # shows the features most likely to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial 6: New Features\n",
    "## Comparing Income, Part B Beneficiaries, and Unhealthy Days\n",
    "## to Poverty Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_name',\n",
       " 'year',\n",
       " 'Population',\n",
       " 'HHI',\n",
       " 'PovertyRate',\n",
       " 'state_id',\n",
       " 'beneficiaries_part_b',\n",
       " 'one_ambulatory_visit',\n",
       " 'diabetic_enrollees_age_65_to_75',\n",
       " 'average_diabetic_enrollees_hemoglobin_a1c_test',\n",
       " 'average_diabetic_enrollees_eye_exam',\n",
       " 'average_diabetic_enrollees_blood_lipids_test',\n",
       " 'average_female_enrollees_age_67_to_69',\n",
       " 'average_female_age_67_to_69_mammogram',\n",
       " 'beneficiaries_part_a_eligible',\n",
       " 'leg_amputations_per_1000_enrollees',\n",
       " 'discharges_ambulatory_care_sensitive_conditions_per_1000_enrollees',\n",
       " 'Days_with_AQI',\n",
       " 'Year',\n",
       " 'Good_Days',\n",
       " 'Moderate_Days',\n",
       " 'Unhealthy_Days',\n",
       " 'Very_Unhealthy_Days',\n",
       " 'Hazardous_Days',\n",
       " 'Days_CO',\n",
       " 'Days_NO2',\n",
       " 'Days_Ozone',\n",
       " 'Days_SO2',\n",
       " 'Days_PM2_5',\n",
       " 'Days_PM10']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify column names \n",
    "\n",
    "list(data_all.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all[['HHI', 'Unhealthy_Days', 'beneficiaries_part_b']]\n",
    "y_data = data_all[['PovertyRate']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test/Split: \n",
    "<br>\n",
    "Use part of our data to train the algorithm, and part of it to evaluate how well the algorithm does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get X and y variables\n",
    "y = y_data\n",
    "X = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HHI</th>\n",
       "      <th>Unhealthy_Days</th>\n",
       "      <th>beneficiaries_part_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3186</th>\n",
       "      <td>46230</td>\n",
       "      <td>2.42</td>\n",
       "      <td>123966.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4890</th>\n",
       "      <td>44587</td>\n",
       "      <td>0.20</td>\n",
       "      <td>534414.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4904</th>\n",
       "      <td>44623</td>\n",
       "      <td>0.00</td>\n",
       "      <td>497193.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3124</th>\n",
       "      <td>48173</td>\n",
       "      <td>0.09</td>\n",
       "      <td>577944.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1084</th>\n",
       "      <td>47212</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1837381.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        HHI  Unhealthy_Days  beneficiaries_part_b\n",
       "3186  46230            2.42              123966.0\n",
       "4890  44587            0.20              534414.0\n",
       "4904  44623            0.00              497193.0\n",
       "3124  48173            0.09              577944.0\n",
       "1084  47212            0.00             1837381.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 83  22 146 ... 219  36 228]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# scale the data\n",
    "X_scaler =  StandardScaler().fit(X_train)\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "# Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)\n",
    "\n",
    "\n",
    "print(encoded_y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "model = SVC(kernel='linear')\n",
    "model.fit(X_train_scaled, encoded_y_train)\n",
    "predictions = model.predict(X_test_scaled)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.5050138681459355\n",
      "Testing Data Score: 0.4440179142674344\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model.score(X_train_scaled, encoded_y_train)}\")\n",
    "print(f\"Testing Data Score: {model.score(X_test_scaled, encoded_y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         7\n",
      "           1       0.30      1.00      0.46         6\n",
      "           2       0.00      0.00      0.00         7\n",
      "           3       1.00      1.00      1.00         6\n",
      "           4       1.00      1.00      1.00         6\n",
      "           5       0.30      0.50      0.37         6\n",
      "           6       0.33      0.50      0.40         6\n",
      "           7       0.00      0.00      0.00         7\n",
      "           8       0.40      0.67      0.50         6\n",
      "           9       0.56      0.83      0.67         6\n",
      "          10       0.67      0.33      0.44         6\n",
      "          11       0.00      0.00      0.00         7\n",
      "          12       0.33      0.17      0.22         6\n",
      "          13       0.80      0.67      0.73         6\n",
      "          14       0.00      0.00      0.00         7\n",
      "          15       0.33      0.17      0.22         6\n",
      "          16       0.25      0.67      0.36         6\n",
      "          17       0.71      0.83      0.77         6\n",
      "          18       0.00      0.00      0.00         7\n",
      "          19       0.17      0.83      0.28         6\n",
      "          20       1.00      1.00      1.00         6\n",
      "          21       0.00      0.00      0.00         7\n",
      "          22       0.20      0.67      0.31         6\n",
      "          23       0.00      0.00      0.00         7\n",
      "          24       0.33      0.33      0.33         6\n",
      "          25       0.57      0.67      0.62         6\n",
      "          26       1.00      1.00      1.00         6\n",
      "          27       0.17      0.17      0.17         6\n",
      "          28       0.25      0.33      0.29         6\n",
      "          29       0.43      0.50      0.46         6\n",
      "          30       0.00      0.00      0.00         7\n",
      "          31       0.43      1.00      0.60         6\n",
      "          32       0.60      0.50      0.55         6\n",
      "          33       0.50      0.83      0.62         6\n",
      "          34       0.55      1.00      0.71         6\n",
      "          35       0.20      0.57      0.30         7\n",
      "          36       0.00      0.00      0.00         7\n",
      "          37       0.86      1.00      0.92         6\n",
      "          38       1.00      1.00      1.00         6\n",
      "          39       0.00      0.00      0.00         7\n",
      "          40       0.46      1.00      0.63         6\n",
      "          41       1.00      1.00      1.00         6\n",
      "          42       0.00      0.00      0.00         7\n",
      "          43       0.00      0.00      0.00         7\n",
      "          44       0.50      0.50      0.50         6\n",
      "          45       1.00      1.00      1.00         6\n",
      "          46       1.00      1.00      1.00         6\n",
      "          47       0.33      0.33      0.33         6\n",
      "          48       1.00      1.00      1.00         6\n",
      "          49       0.33      0.33      0.33         6\n",
      "          50       0.50      1.00      0.67         6\n",
      "          51       0.00      0.00      0.00         6\n",
      "          52       0.60      1.00      0.75         6\n",
      "          53       0.67      0.33      0.44         6\n",
      "          54       0.19      1.00      0.32         6\n",
      "          55       1.00      1.00      1.00         6\n",
      "          56       1.00      1.00      1.00         6\n",
      "          57       0.60      1.00      0.75         6\n",
      "          58       0.00      0.00      0.00         6\n",
      "          59       0.00      0.00      0.00         7\n",
      "          60       0.50      0.17      0.25         6\n",
      "          61       0.46      1.00      0.63         6\n",
      "          62       1.00      0.17      0.29         6\n",
      "          63       1.00      0.50      0.67         6\n",
      "          64       0.17      0.17      0.17         6\n",
      "          65       0.75      1.00      0.86         6\n",
      "          66       0.17      0.17      0.17         6\n",
      "          67       0.17      0.17      0.17         6\n",
      "          68       1.00      0.50      0.67         6\n",
      "          69       0.46      1.00      0.63         6\n",
      "          70       0.00      0.00      0.00         7\n",
      "          71       1.00      1.00      1.00         6\n",
      "          72       0.00      0.00      0.00         7\n",
      "          73       1.00      1.00      1.00         6\n",
      "          74       0.00      0.00      0.00         7\n",
      "          75       1.00      1.00      1.00         6\n",
      "          76       0.00      0.00      0.00         7\n",
      "          77       1.00      1.00      1.00         6\n",
      "          78       1.00      1.00      1.00         6\n",
      "          79       0.00      0.00      0.00         7\n",
      "          80       0.00      0.00      0.00         7\n",
      "          81       0.00      0.00      0.00         7\n",
      "          82       0.38      1.00      0.55         6\n",
      "          83       1.00      1.00      1.00         6\n",
      "          84       0.38      1.00      0.55         6\n",
      "          85       0.00      0.00      0.00         7\n",
      "          86       0.00      0.00      0.00         6\n",
      "          87       0.55      1.00      0.71         6\n",
      "          88       0.00      0.00      0.00         6\n",
      "          89       0.60      1.00      0.75         6\n",
      "          90       1.00      0.50      0.67         6\n",
      "          91       1.00      1.00      1.00         6\n",
      "          92       0.25      0.33      0.29         6\n",
      "          93       0.00      0.00      0.00         7\n",
      "          94       0.00      0.00      0.00         7\n",
      "          95       1.00      1.00      1.00         6\n",
      "          96       0.00      0.00      0.00         7\n",
      "          97       0.15      1.00      0.27         6\n",
      "          98       0.20      0.33      0.25         6\n",
      "          99       1.00      1.00      1.00         6\n",
      "         100       0.17      0.67      0.28         6\n",
      "         101       0.25      0.17      0.20         6\n",
      "         102       0.29      1.00      0.44         6\n",
      "         103       0.50      1.00      0.67         6\n",
      "         104       1.00      1.00      1.00         6\n",
      "         105       0.14      0.17      0.15         6\n",
      "         106       1.00      1.00      1.00         6\n",
      "         107       0.17      0.33      0.22         6\n",
      "         108       1.00      1.00      1.00         6\n",
      "         109       0.00      0.00      0.00         7\n",
      "         110       0.00      0.00      0.00         7\n",
      "         111       0.00      0.00      0.00         7\n",
      "         112       0.27      1.00      0.43         6\n",
      "         113       0.38      0.50      0.43         6\n",
      "         114       0.00      0.00      0.00         7\n",
      "         115       1.00      1.00      1.00         6\n",
      "         116       1.00      1.00      1.00         6\n",
      "         117       1.00      1.00      1.00         6\n",
      "         118       0.38      1.00      0.55         6\n",
      "         119       0.67      1.00      0.80         6\n",
      "         120       0.00      0.00      0.00         6\n",
      "         121       0.00      0.00      0.00         7\n",
      "         122       1.00      1.00      1.00         6\n",
      "         123       0.00      0.00      0.00         6\n",
      "         124       0.00      0.00      0.00         7\n",
      "         125       0.00      0.00      0.00         7\n",
      "         126       0.20      0.17      0.18         6\n",
      "         127       0.55      1.00      0.71         6\n",
      "         128       0.00      0.00      0.00         7\n",
      "         129       0.00      0.00      0.00         7\n",
      "         130       0.00      0.00      0.00         6\n",
      "         131       0.67      1.00      0.80         6\n",
      "         132       0.40      0.33      0.36         6\n",
      "         133       0.13      0.67      0.22         6\n",
      "         134       1.00      1.00      1.00         6\n",
      "         135       0.36      0.83      0.50         6\n",
      "         136       0.00      0.00      0.00         6\n",
      "         137       0.33      0.17      0.22         6\n",
      "         138       0.00      0.00      0.00         7\n",
      "         139       0.33      0.33      0.33         6\n",
      "         140       1.00      0.33      0.50         6\n",
      "         141       0.00      0.00      0.00         6\n",
      "         142       0.00      0.00      0.00         6\n",
      "         143       0.00      0.00      0.00         7\n",
      "         144       0.00      0.00      0.00         6\n",
      "         145       1.00      1.00      1.00         6\n",
      "         146       0.46      1.00      0.63         6\n",
      "         147       0.00      0.00      0.00         6\n",
      "         148       0.00      0.00      0.00         6\n",
      "         149       0.00      0.00      0.00         6\n",
      "         150       0.22      0.33      0.27         6\n",
      "         151       0.00      0.00      0.00         7\n",
      "         152       0.00      0.00      0.00         7\n",
      "         153       0.00      0.00      0.00         7\n",
      "         154       0.50      0.50      0.50         6\n",
      "         155       0.67      0.33      0.44         6\n",
      "         156       0.00      0.00      0.00         7\n",
      "         157       0.00      0.00      0.00         6\n",
      "         158       0.00      0.00      0.00         6\n",
      "         159       0.46      1.00      0.63         6\n",
      "         160       0.20      0.33      0.25         6\n",
      "         161       1.00      0.33      0.50         6\n",
      "         162       0.00      0.00      0.00         6\n",
      "         163       0.20      0.17      0.18         6\n",
      "         164       0.38      0.83      0.53         6\n",
      "         165       0.67      0.67      0.67         6\n",
      "         166       0.42      0.83      0.56         6\n",
      "         167       0.00      0.00      0.00         6\n",
      "         168       0.40      0.67      0.50         6\n",
      "         169       0.50      0.83      0.62         6\n",
      "         170       1.00      0.83      0.91         6\n",
      "         171       0.00      0.00      0.00         7\n",
      "         172       0.25      0.33      0.29         6\n",
      "         173       0.00      0.00      0.00         7\n",
      "         174       1.00      1.00      1.00         6\n",
      "         175       1.00      0.33      0.50         6\n",
      "         176       0.00      0.00      0.00         6\n",
      "         177       0.17      0.83      0.29         6\n",
      "         178       0.67      0.33      0.44         6\n",
      "         179       0.00      0.00      0.00         7\n",
      "         180       1.00      1.00      1.00         6\n",
      "         181       0.56      0.83      0.67         6\n",
      "         182       0.00      0.00      0.00         7\n",
      "         183       0.67      0.33      0.44         6\n",
      "         184       0.20      0.17      0.18         6\n",
      "         185       1.00      1.00      1.00         6\n",
      "         186       0.29      0.33      0.31         6\n",
      "         187       0.00      0.00      0.00         6\n",
      "         188       0.00      0.00      0.00         7\n",
      "         189       0.25      0.33      0.29         6\n",
      "         190       0.12      0.17      0.14         6\n",
      "         191       0.00      0.00      0.00         7\n",
      "         192       0.00      0.00      0.00         6\n",
      "         193       0.50      0.50      0.50         6\n",
      "         194       1.00      0.83      0.91         6\n",
      "         195       0.31      0.67      0.42         6\n",
      "         196       0.00      0.00      0.00         7\n",
      "         197       0.11      0.17      0.13         6\n",
      "         198       1.00      1.00      1.00         6\n",
      "         199       0.18      0.33      0.24         6\n",
      "         200       1.00      0.33      0.50         6\n",
      "         201       0.00      0.00      0.00         7\n",
      "         202       0.42      0.83      0.56         6\n",
      "         203       0.86      1.00      0.92         6\n",
      "         204       1.00      1.00      1.00         6\n",
      "         205       0.20      0.67      0.31         6\n",
      "         206       0.31      0.67      0.42         6\n",
      "         207       0.50      0.33      0.40         6\n",
      "         208       0.46      1.00      0.63         6\n",
      "         209       0.00      0.00      0.00         7\n",
      "         210       0.00      0.00      0.00         7\n",
      "         211       0.00      0.00      0.00         7\n",
      "         212       0.20      0.17      0.18         6\n",
      "         213       0.00      0.00      0.00         7\n",
      "         214       0.55      1.00      0.71         6\n",
      "         215       0.46      1.00      0.63         6\n",
      "         216       0.60      0.50      0.55         6\n",
      "         217       0.50      1.00      0.67         6\n",
      "         218       0.46      1.00      0.63         6\n",
      "         219       0.20      0.33      0.25         6\n",
      "         220       0.08      0.17      0.11         6\n",
      "         221       1.00      1.00      1.00         6\n",
      "         222       0.50      0.17      0.25         6\n",
      "         223       0.00      0.00      0.00         6\n",
      "         224       0.00      0.00      0.00         7\n",
      "         225       0.00      0.00      0.00         7\n",
      "         226       0.00      0.00      0.00         7\n",
      "         227       0.57      0.67      0.62         6\n",
      "         228       0.46      1.00      0.63         6\n",
      "         229       0.00      0.00      0.00         7\n",
      "         230       0.00      0.00      0.00         7\n",
      "         231       0.29      1.00      0.44         6\n",
      "         232       0.00      0.00      0.00         7\n",
      "         233       0.46      1.00      0.63         6\n",
      "         234       0.00      0.00      0.00         6\n",
      "         235       0.67      0.67      0.67         6\n",
      "         236       0.00      0.00      0.00         7\n",
      "         237       0.00      0.00      0.00         7\n",
      "         238       0.46      1.00      0.63         6\n",
      "         239       0.00      0.00      0.00         6\n",
      "         240       0.00      0.00      0.00         6\n",
      "         241       0.20      0.17      0.18         6\n",
      "         242       0.00      0.00      0.00         7\n",
      "         243       0.00      0.00      0.00         7\n",
      "         244       0.16      0.83      0.26         6\n",
      "         245       1.00      1.00      1.00         6\n",
      "         246       1.00      1.00      1.00         6\n",
      "         247       1.00      1.00      1.00         6\n",
      "         248       1.00      1.00      1.00         6\n",
      "         249       1.00      1.00      1.00         6\n",
      "\n",
      "    accuracy                           0.44      1563\n",
      "   macro avg       0.38      0.46      0.39      1563\n",
      "weighted avg       0.36      0.44      0.37      1563\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\me\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Calculate classification report\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(encoded_y_test, predictions))\n",
    "\n",
    "# low precision scores indicate we need different data to evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_all[\"PovertyRate\"]\n",
    "target_names = data_all[\"PovertyRate\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data_all.drop(\"PovertyRate\", axis=1)\n",
    "data = data.drop(\"state_name\", axis=1)\n",
    "feature_names = data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown label type: 'continuous'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-79-919dfd680ef1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDecisionTreeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    892\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 894\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    895\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mis_classification\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 181\u001b[1;33m             \u001b[0mcheck_classification_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    182\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonAdv\\lib\\site-packages\\sklearn\\utils\\multiclass.py\u001b[0m in \u001b[0;36mcheck_classification_targets\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    170\u001b[0m     if y_type not in ['binary', 'multiclass', 'multiclass-multioutput',\n\u001b[0;32m    171\u001b[0m                       'multilabel-indicator', 'multilabel-sequences']:\n\u001b[1;32m--> 172\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown label type: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unknown label type: 'continuous'"
     ]
    }
   ],
   "source": [
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=200)\n",
    "rf = rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(zip(rf.feature_importances_, feature_names), reverse=True)\n",
    "\n",
    "# shows the features most likely to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Highest Classification Scores for SVC models:\n",
    "## Trial 4 - Comparing Income and Part B Beneficiaries to Poverty Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression model: Poverty Rate vs. Medicare Part B Beneficiaries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the data to X and y\n",
    "\n",
    "X = data_all[['beneficiaries_part_b']]\n",
    "y = data_all[['PovertyRate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model using LinearRegression\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.04473806377724199\n",
      "Testing Score: 0.026497095521388903\n"
     ]
    }
   ],
   "source": [
    "# Fit the model to the training data and calculate the scores for the training and testing data\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "training_score = model.score(X_train, y_train)\n",
    "testing_score = model.score(X_test, y_test)\n",
    "\n",
    "print(f\"Training Score: {training_score}\")\n",
    "print(f\"Testing Score: {testing_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Residuals for the Training and Testing data\n",
    "\n",
    "plt.scatter(model.predict(X_train), model.predict(X_train) - y_train, c=\"blue\", label=\"Training Data\")\n",
    "plt.scatter(model.predict(X_test), model.predict(X_test) - y_test, c=\"orange\", label=\"Testing Data\")\n",
    "plt.legend()\n",
    "plt.hlines(y=0, xmin=y.min(), xmax=y.max())\n",
    "plt.title(\"Residual Plot\")\n",
    "plt.savefig(\"D:\\\\BBC\\\\COPY_but-ind-data-pt-06-2020-u-c\\\\Linear_Regression_Model.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13.48897331],\n",
       "       [16.41956992],\n",
       "       [13.47096432],\n",
       "       ...,\n",
       "       [14.02432792],\n",
       "       [13.84701037],\n",
       "       [14.05532685]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make predictions\n",
    "\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = regressor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The predictions variable holds the predicted values of the features stored in x_test. Since we used the train_test_split \n",
    "# method to store the real values in y_test, we compare the values of the predictions array with the values of y_test by\n",
    "# using a scatterplot.\n",
    "\n",
    "plt.scatter(y_pred, y_test)\n",
    "plt.savefig(\"D:\\\\BBC\\\\COPY_but-ind-data-pt-06-2020-u-c\\\\Linear_Regression_Model_validation.png\")\n",
    "plt.show()\n",
    "\n",
    "# predicted values are very close to the actual values for the observations in the data set. A perfectly straight diagonal \n",
    "# line in this scatterplot would indicate that our model perfectly predicted the y-array values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot its residuals, which are the difference between the actual y-array values and the predicted y-array values.\n",
    "\n",
    "plt.hist(y_test - y_pred)\n",
    "plt.savefig(\"D:\\\\BBC\\\\COPY_but-ind-data-pt-06-2020-u-c\\\\Linear_Regression_Model_validation_hist.png\")\n",
    "plt.show()\n",
    "\n",
    "# residuals from our machine learning model appear to be close to normally distributed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the results\n",
    "\n",
    "# x_train=X_train.values.reshape(-1, 1)\n",
    "# Y_train=y_train.values.reshape(-1, 1)\n",
    "# x_test=X_test.reshape(-1, 1)\n",
    "\n",
    "# plt.scatter(x_train, Y_train, color='blue')\n",
    "# plt.plot(x_train, regressor.predict(x_test), color='red')\n",
    "# plt.title('Poverty Rate vs. Household Income and Medicare Part B Beneficiaries')\n",
    "# plt.xlabel('Household Income and Medicare Part B Beneficiaries')\n",
    "# plt.ylabel('Poverty Rate')\n",
    "\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python [conda env:PythonAdv]",
   "language": "python",
   "name": "conda-env-PythonAdv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
